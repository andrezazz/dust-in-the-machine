{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from tqdm import notebook # Library for displaying progress bar\n",
    "np.random.seed(500)\n",
    "\n",
    "# Set the desired bin size\n",
    "bin_size = 15\n",
    "\n",
    "# Sets the output filename\n",
    "filename = 'dust_training_data_ordered_logit_bin_15_drop_1_bin.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select a pair of snapshots, the lower index is the input and the higher index is the output. Then combined bins together based on the number of desired bins. Ie if the bin size is 15, every 10 bins will be combined into one. Y is randomnly sampled from the bins. \n",
    "\n",
    "Tried the following transformations:\n",
    "- None\n",
    "- Log space\n",
    "- 1 / log space\n",
    "- normalized output\n",
    "- normalized input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(i, snapshot_count, rhod, time, bin_size=15, num_bins=151):\n",
    "    \"\"\" Creates a training sample from two points in time. Selects a random output bin for y, and saves the output bins for comparison\"\"\"\n",
    "    # First sample will always be the first and last element\n",
    "    if i == 0:\n",
    "        idxs = [0, snapshot_count-1]\n",
    "    else:\n",
    "        # Pick two indexes for snapshots (lowest = input, highest = output)\n",
    "        idxs = sorted([random.randint(0,snapshot_count-1) for _ in range(2)])\n",
    "    input_a = rhod[idxs[0]]\n",
    "    output_a = rhod[idxs[1]]\n",
    "\n",
    "    new_input_bins = []\n",
    "    new_output_bins = []\n",
    "    input_bin_sum = np.sum(input_a)\n",
    "    output_bin_sum = np.sum(output_a)\n",
    "    for i in range(bin_size):\n",
    "        # Get the start index of the bin\n",
    "        start = i * math.floor(num_bins/bin_size)\n",
    "        # Get the end index\n",
    "        end = (i+1) * math.floor(num_bins/bin_size)\n",
    "        # Include bin 150 in the last new bin (151 does not divide into 15 evenly for example)\n",
    "        if i == bin_size-1:\n",
    "            end+=num_bins % bin_size\n",
    "            \n",
    "        # Get the old bins and sum them together to create the new one\n",
    "        # Also normalize the input bins\n",
    "        # Could add a statement here to leave out one of the input bins\n",
    "        new_input_bin = np.sum(input_a[start:end]) / input_bin_sum\n",
    "        if new_input_bin < 10^-30:\n",
    "            new_input_bin = 0\n",
    "        # Skip the first bin\n",
    "        if i > 0:\n",
    "            new_input_bins.append(new_input_bin)\n",
    "        \n",
    "        # Normalize the output bin so we can compare the prob distribution to it\n",
    "        new_output_bin = np.sum(output_a[start:end]) / output_bin_sum\n",
    "        if new_output_bin < 10^-30:\n",
    "            new_output_bin = 0\n",
    "        new_output_bins.append(new_output_bin)\n",
    "        \n",
    "    # Select the highest density bin => highest prob\n",
    "    y = np.argmax(new_output_bins)\n",
    "    # Time of the input\n",
    "    t = time[idxs[0]]\n",
    "        \n",
    "    # Difference of time in seconds between two snapshots\n",
    "    delta_t = time[idxs[1]] - t\n",
    "    \n",
    "    row = np.concatenate([input_params,new_input_bins,[t, delta_t, y], new_output_bins])\n",
    "    return row\n",
    "\n",
    "def write_to_file(data, header=True, bin_size=15, batch=False):\n",
    "    \"\"\" Helper method to write training data to a file\"\"\"\n",
    "    columns = ['R', 'Mstar', 'alpha', 'd2g', 'sigma', 'Tgas'] + [f'Input_Bin_{i}' for i in range(bin_size - 1)] + ['t','Delta_t', 'y'] + [f'Output_Bin_{i}' for i in range(bin_size)]\n",
    "    df = pd.DataFrame(res, columns=columns)\n",
    "\n",
    "    # If writing in batch set the file mode to append\n",
    "    mode = 'a' if batch else 'w'\n",
    "    df.to_csv(filename, chunksize=100000, mode=mode, header=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95dc99c23c43609aa5d5d1020991cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_data_path = \"/project/SDS-capstones-kropko21/uva-astronomy/data/dust_coag_data_v1\"\n",
    "data_group = \"combined_v1\"\n",
    "\n",
    "# Store formatted data for training\n",
    "res = []\n",
    "\n",
    "chunk_size = 1000\n",
    "# Set this to a smaller number to get a smaller training set\n",
    "model_count = 10000\n",
    "writes = 0\n",
    "for d in notebook.tqdm(range(model_count)):\n",
    "    data_set = data_set = str(d).zfill(5)\n",
    "\n",
    "    data_dir = f\"{root_data_path}/{data_group}/data_{data_set}\"\n",
    "\n",
    "    input_params = None\n",
    "    # Open and extract the input parameters\n",
    "    with open(os.path.join(root_data_path, \"model_dict_v1.json\")) as f:\n",
    "        model_dict = json.load(f)\n",
    "        input_dict = model_dict[data_set]\n",
    "        input_params = [input_dict['R'], input_dict['Mstar'], input_dict['alpha'],input_dict['d2g'], input_dict['sigma'], input_dict['Tgas']]\n",
    "\n",
    "    try:\n",
    "        # `rho_dat`: The dust mass density (in g/cm^3) in each particle size/bin at a given snapshot in time. This is the main \"output\", i.e., the primary result, of any given model.\n",
    "        rhod = np.loadtxt(os.path.join(data_dir,\"rho_d.dat\"))\n",
    "        # Replace NaNs with 0s\n",
    "        rhod = np.nan_to_num(rhod)\n",
    "        # Replace negative values with 0s\n",
    "        rhod = np.where(rhod<0, 0, rhod) \n",
    "        \n",
    "        # `a_grid.dat`: The dust particle size in each \"bin\" in centimeters.\n",
    "        a_grid = np.loadtxt(os.path.join(data_dir, 'a_grid.dat'))\n",
    "\n",
    "        # `time.dat`: The time of each snapshot (in seconds).\n",
    "        time = np.loadtxt(os.path.join(data_dir, \"time.dat\"))\n",
    "    except Exception as e:\n",
    "        print(f'model {d} skipped')\n",
    "        import traceback\n",
    "        print(traceback.print_exc())\n",
    "        continue\n",
    "\n",
    "    snapshot_count = len(rhod)\n",
    "\n",
    "    # Set the number of samples\n",
    "    if snapshot_count > 15:\n",
    "        # Set the max to 100 for time as 15 cHr 2 is about 100\n",
    "        samples = 100\n",
    "    else:\n",
    "        # The number of pairs\n",
    "        samples = int(math.factorial(snapshot_count) / math.factorial(2) / math.factorial(snapshot_count-2))\n",
    "    \n",
    "    samples += 1\n",
    "    for i in range(samples):\n",
    "        row = process_sample(i, snapshot_count, rhod, time, bin_size=bin_size)\n",
    "        res.append(row)\n",
    "        \n",
    "    # Write to csv every x models to avoid oom\n",
    "    if d != 0 and d % chunk_size == (model_count - 1) % chunk_size:\n",
    "        writes += 1\n",
    "        # Only write the header on first chunk\n",
    "        header = writes == 1\n",
    "        write_to_file(res, header, bin_size=bin_size, batch=True)\n",
    "        res = []\n",
    "    \n",
    "# Write out the entire file at the end\n",
    "#write_to_file(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    210912\n",
       "5.0     145724\n",
       "6.0      82791\n",
       "7.0      56221\n",
       "8.0      44341\n",
       "9.0      38729\n",
       "10.0     36739\n",
       "11.0     33821\n",
       "4.0      32690\n",
       "12.0     32674\n",
       "13.0     27738\n",
       "2.0      22063\n",
       "3.0      21256\n",
       "1.0       8095\n",
       "0.0       6544\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df = pd.read_csv(filename)\n",
    "read_df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into train and test and use the mord package for ordered logistic regression. We extracted the probabilities and scored the model fit with negagative mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install mord\n",
    "import mord\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_test_train(data_set_path, test_size=0.10):\n",
    "    \"\"\" Splits a given csv file into testing and training. Target column must be y \"\"\"\n",
    "    # Make sure the columns are set\n",
    "    data_set = pd.read_csv(data_set_path)\n",
    "\n",
    "    # Shuffle the data\n",
    "    data_set = data_set.sample(frac=1, random_state=0)\n",
    " \n",
    "    # Select all except y column and the output bins for the predictors\n",
    "    data_set_X = data_set.drop(['y'] + [f'Output_Bin_{i}' for i in range(bin_size)], axis=1)\n",
    "    \n",
    "    # Select just y column and output bins\n",
    "    data_set_Y = data_set[['y'] + [f'Output_Bin_{i}' for i in range(bin_size)]]\n",
    "\n",
    "    #Split into training and test data\n",
    "    return train_test_split(data_set_X,\n",
    "                            data_set_Y,\n",
    "                            test_size=test_size, \n",
    "                            random_state=300)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_test_train(\"dust_training_data_ordered_logit_bin_15_drop_small.csv\")\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "logistic_model = mord.LogisticIT()\n",
    "#logistic_model = LogisticRegression(penalty=\"elasticnet\", solver='saga', multi_class='multinomial', l1_ratio=0.5)\n",
    "# Fit only on the y column\n",
    "logistic_model.fit(X_train, y_train['y'])\n",
    "\n",
    "# Obtain the probability distribution of the class\n",
    "probs = logistic_model.predict_proba(X_test)\n",
    "\n",
    "# Obtain the negative mean absolute error\n",
    "score = logistic_model.score(X_test, y_test['y'])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    211155\n",
       "5.0     145464\n",
       "6.0      83189\n",
       "7.0      56260\n",
       "8.0      44278\n",
       "9.0      38514\n",
       "10.0     36641\n",
       "11.0     33810\n",
       "4.0      32672\n",
       "12.0     32648\n",
       "13.0     27744\n",
       "2.0      22071\n",
       "3.0      21279\n",
       "1.0       8049\n",
       "0.0       6564\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the counts of our labels\n",
    "#pd.read_csv(\"dust_training_data_ordered_logit_bin_15_3.csv\")['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a plot of an observation and the predicted probability distribution. We also calculated the entropy for each test observation and the predicted observation which is the Kullback-Leibler divergence.\n",
    "\n",
    "On the full models with a bin size of 15, entropy averaged around 2.4 which is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import entropy, kstest\n",
    "\n",
    "# Select a test observation to graph\n",
    "test_obs = probs[5]\n",
    "cols = [f'Output_Bin_{i}' for i in range(bin_size)]\n",
    "\n",
    "# Get the true distribution\n",
    "y_obs = y_test.iloc[5][cols]\n",
    "\n",
    "# Plot the two together\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(test_obs)\n",
    "plt.plot(y_obs)\n",
    "plt.show()\n",
    "\n",
    "#Uniform distribution\n",
    "uniform_probs = np.full(\n",
    "    shape=bin_size,\n",
    "    fill_value=1/bin_size,\n",
    "   dtype=np.float)\n",
    "\n",
    "uniform_probs = np.repeat([uniform_probs], len(y_test),0)\n",
    "\n",
    "def get_entropy_from_predictions(y_test, preds):\n",
    "    # Get entropy for all\n",
    "    entropys = []\n",
    "    for idx, prob in enumerate(preds):\n",
    "        output = y_test.iloc[idx][[f'Output_Bin_{i}' for i in range(bin_size)]]\n",
    "        # To compute the entropies, the length of the probability list and the bin list must be equal\n",
    "        # If your training data does not include all bins, you'll need to fill in 0s for the probability matrix\n",
    "        p = prob\n",
    "    \n",
    "        # Reshape the probabilities for missing ones\n",
    "        if prob.shape[0] !=output.shape[0]:\n",
    "            new_prob = np.zeros(bin_size)\n",
    "            for y in np.unique(y_test):\n",
    "                new_prob[y] = output[y]\n",
    "            p = new_prob\n",
    "        \n",
    "        ent = entropy(p, output.values)\n",
    "        entropys.append(ent)\n",
    "    return entropys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights for ordered logistic regression are [-3.62851363e-23  6.01253750e-24  5.99645927e-26  1.81367751e-24\n",
    "  7.60720374e-21  4.02295591e-22  1.20522032e-26  5.83738829e-26\n",
    "  1.06397716e-25  1.91096479e-25  2.70059363e-25  4.59112014e-25\n",
    "  6.51787801e-25  4.56346698e-25  3.46132030e-25  2.89165514e-25\n",
    "  2.58570675e-25  2.38370174e-25  2.06436920e-25  1.57797803e-25\n",
    "  2.31083822e-24  6.22381710e-13  2.56913296e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_drop1, X_test_drop1, y_train_drop1, y_test_drop1 = create_test_train(\"dust_training_data_ordered_logit_bin_15_drop_1_bin.csv\")\n",
    "y_train_drop1 = y_train_drop1.astype(int)\n",
    "\n",
    "logistic_model_drop1 = mord.LogisticIT()\n",
    "# Fit only on the y column\n",
    "logistic_model_drop1.fit(X_train_drop1, y_train_drop1['y'])\n",
    "\n",
    "# Obtain the probability distribution of the class\n",
    "probs_drop1 = logistic_model_drop1.predict_proba(X_test_drop1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays the entropy for the uniform distribution, logistic regression with 15 bins, and logistic regression with 14 input bins (drops the first bin). The entropy does not change much between dropping a bin or not. They are better than just a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy for logistic regression:                   0\n",
      "count  80034.000000\n",
      "mean      76.734436\n",
      "std      164.832547\n",
      "min        0.029114\n",
      "25%        1.782056\n",
      "50%        4.463710\n",
      "75%       75.808856\n",
      "max     1000.000000\n",
      "Entropy for logistic regression dropping first bin:                   0\n",
      "count  80034.000000\n",
      "mean      76.800328\n",
      "std      165.050971\n",
      "min        0.063576\n",
      "25%        1.773307\n",
      "50%        4.453947\n",
      "75%       74.706034\n",
      "max     1000.000000\n",
      "Entropy for uniform:                   0\n",
      "count  80034.000000\n",
      "mean     100.335601\n",
      "std      145.600085\n",
      "min        0.804889\n",
      "25%       43.827432\n",
      "50%       75.423806\n",
      "75%      119.465119\n",
      "max     1000.000000\n"
     ]
    }
   ],
   "source": [
    "df_entropy = pd.DataFrame(get_entropy_from_predictions(y_test, probs))\n",
    "\n",
    "df_entropy_uniform = pd.DataFrame(get_entropy_from_predictions(y_test,uniform_probs))\n",
    "\n",
    "df_entropy_drop1 = pd.DataFrame(get_entropy_from_predictions(y_test_drop1,probs_drop1))\n",
    "\n",
    "#Replace inf with large numbers\n",
    "df_entropy.replace(np.inf, 1000, inplace=True)\n",
    "df_entropy_uniform.replace(np.inf, 1000, inplace=True)\n",
    "df_entropy_drop1.replace(np.inf, 1000, inplace=True)\n",
    "\n",
    "print(f\"Entropy for logistic regression: {df_entropy.describe()}\")\n",
    "print(f\"Entropy for logistic regression dropping first bin: {df_entropy_drop1.describe()}\")\n",
    "\n",
    "#df_entropy_uniform = pd.DataFrame(entropys_uniform)\n",
    "print(f\"Entropy for uniform: {df_entropy_uniform.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display our logistic model coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: [-3.62851363e-23  6.01253750e-24  5.99645927e-26  1.81367751e-24\n",
      "  7.60720374e-21  4.02295591e-22  1.20522032e-26  5.83738829e-26\n",
      "  1.06397716e-25  1.91096479e-25  2.70059363e-25  4.59112014e-25\n",
      "  6.51787801e-25  4.56346698e-25  3.46132030e-25  2.89165514e-25\n",
      "  2.58570675e-25  2.38370174e-25  2.06436920e-25  1.57797803e-25\n",
      "  2.31083822e-24  6.22381710e-13  2.56913296e-12]\n",
      "Logistic drop one bin: [-3.78959554e-23  5.94791322e-24  5.92617749e-26  1.79905699e-24\n",
      "  7.54390379e-21  3.98738836e-22  5.68177097e-26  1.03798282e-25\n",
      "  1.86072622e-25  2.62882045e-25  4.48680932e-25  6.47022621e-25\n",
      "  4.52827258e-25  3.43455297e-25  2.86832387e-25  2.57329069e-25\n",
      "  2.36530105e-25  2.03673983e-25  1.54993306e-25  2.29583684e-24\n",
      "  6.19530848e-13  2.59593687e-12]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic: {logistic_model.coef_}\")\n",
    "print(f\"Logistic drop one bin: {logistic_model_drop1.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a Softmax(multinomial) regression with the normalized data using Gradient Descent. Got an entropy of about 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/mlxtend/classifier/softmax_regression.py:99: RuntimeWarning: divide by zero encountered in log\n",
      "  return - np.sum(np.log(output) * (y_target), axis=1)\n",
      "/home/keh4nb/.local/lib/python3.7/site-packages/mlxtend/classifier/softmax_regression.py:99: RuntimeWarning: invalid value encountered in multiply\n",
      "  return - np.sum(np.log(output) * (y_target), axis=1)\n",
      "Iteration: 100/100 | Cost nan | Elapsed: 0:03:32 | ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlxtend.classifier.softmax_regression.SoftmaxRegression at 0x7fb03de440d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install mlxtend \n",
    "from mlxtend.classifier import SoftmaxRegression\n",
    "\n",
    "lr = SoftmaxRegression(eta=0.01, \n",
    "                       epochs=100, # Passes over the training sets\n",
    "                       minibatches=1, # Gradient descent learning\n",
    "                       l2=0.5, # L2 regularization\n",
    "                       random_seed=1,\n",
    "                       print_progress=3)\n",
    "lr.fit(X_train_drop1.to_numpy(), y_train_drop1['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "count  80034.000000\n",
      "mean      30.790867\n",
      "std       70.000785\n",
      "min        0.656108\n",
      "25%        2.192372\n",
      "50%        3.386435\n",
      "75%       17.665226\n",
      "max     1000.000000\n"
     ]
    }
   ],
   "source": [
    "# Extract probabilities and show entropy\n",
    "probs_softmax = lr.predict_proba(X_test_drop1.to_numpy())\n",
    "df_softmax_entropy = pd.DataFrame(get_entropy_from_predictions(y_test_drop1, probs_softmax))\n",
    "df_softmax_entropy.replace(np.inf, 1000, inplace=True)\n",
    "\n",
    "# Select a test observation to graph\n",
    "test_obs = probs_softmax[5]\n",
    "cols = [f'Output_Bin_{i}' for i in range(bin_size)]\n",
    "\n",
    "# Get the true distribution\n",
    "y_obs = y_test_drop1.iloc[5][cols]\n",
    "\n",
    "# Plot the two together\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(test_obs, color='blue')\n",
    "plt.plot(y_obs, color='orange')\n",
    "plt.show()\n",
    "\n",
    "print(df_softmax_entropy.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.60483087e+05  1.75962898e+06  2.11386539e+06  3.33026895e+05\n",
      "   3.10449298e+06  1.47032735e+06  1.00298730e+06  7.97372403e+05\n",
      "   1.43149018e+05  1.84633574e+05  1.49006079e+05 -5.21337993e+05\n",
      "  -5.15819052e+05 -7.14679139e+05 -1.02671369e+07]\n",
      " [-5.62285066e+03 -2.23101522e+02  1.22366930e+03  2.56028038e+03\n",
      "  -3.28867310e+03 -4.01205023e+04  3.96008004e+03  6.98230248e+03\n",
      "   1.07136132e+04  7.97126295e+03  9.62752895e+03  5.23261581e+03\n",
      "   8.63138670e+03  5.13691524e+03 -1.27845314e+04]\n",
      " [ 2.75749234e+02  4.59826138e+02  1.29903592e+03  1.27285715e+03\n",
      "   6.23996664e+02 -1.14635817e+03  2.64040531e+01  2.11411168e+02\n",
      "   2.11725832e+02 -2.35498812e+01 -1.29975370e+02 -2.12462673e+02\n",
      "  -1.72201329e+02 -2.23915277e+02 -2.47255479e+03]\n",
      " [-1.46527404e+03  7.21645118e+02  8.75663690e+02 -1.21635232e+03\n",
      "  -1.29122284e+03 -2.02717878e+04 -3.01800485e+03 -4.87474856e+02\n",
      "   6.45625889e+02  2.03079726e+03  3.67809327e+03  1.82479278e+03\n",
      "   1.84618484e+03  1.64625876e+03  1.44810803e+04]\n",
      " [-7.07211279e+06 -4.03744438e+06 -9.98635564e+06 -8.54346691e+06\n",
      "  -1.79027271e+07 -9.64996073e+07 -3.43641214e+07 -1.67212061e+07\n",
      "  -6.33194889e+06 -3.99149268e+06 -2.38236270e+06 -2.19235809e+06\n",
      "   1.49888625e+07 -3.25913758e+05  1.95362255e+08]\n",
      " [-4.02057440e+05 -2.16076881e+05 -4.85956684e+05 -3.43492763e+05\n",
      "  -8.57971767e+05 -4.41435224e+06 -9.86721585e+05 -2.76700776e+05\n",
      "   1.71659635e+05  1.45207788e+05  2.66536079e+05  2.59617511e+05\n",
      "   6.76711261e+05  3.57663126e+05  6.10593474e+06]\n",
      " [ 5.03361062e+02  1.69566298e+03  3.18770013e+03  1.78785179e+03\n",
      "   1.76463285e+03 -3.87882493e+02  2.01431637e+02  3.03833611e+02\n",
      "   2.62596662e+02 -1.00762265e+02 -1.99034687e+02 -5.04391259e+02\n",
      "  -4.49131171e+02 -5.87189487e+02 -7.47867131e+03]\n",
      " [ 9.56728246e+01  9.68333548e+02  3.88951393e+03  2.55669529e+03\n",
      "   2.09999645e+03  1.03370139e+03  4.13926638e+02  2.48491559e+02\n",
      "   3.54595211e+02  2.61153265e+01 -1.18659088e+01 -4.02538988e+02\n",
      "  -3.76474704e+02 -6.47682800e+02 -1.02484945e+04]\n",
      " [-4.01855434e+02 -3.82312231e+02  8.48332112e+02  3.56916195e+03\n",
      "   2.48046553e+03  4.80402672e+03  1.89618698e+03  6.39200434e+02\n",
      "   4.34492633e+02 -3.95294017e+00 -4.31608357e+01 -4.02898176e+02\n",
      "  -2.46286580e+02 -5.72970615e+02 -1.26184127e+04]\n",
      " [-5.54189945e+02 -4.81401101e+02 -1.14359540e+03  6.21952159e+02\n",
      "   3.60540418e+03  8.76650396e+03  4.46426050e+03  1.61501935e+03\n",
      "   9.67571777e+02  2.05390170e+02 -1.37796158e+01 -5.99955313e+02\n",
      "  -3.38994403e+02 -6.84688845e+02 -1.64294780e+04]\n",
      " [-8.34459084e+02 -6.72810408e+02 -1.60896154e+03 -1.39368377e+03\n",
      "  -1.78220119e+03  1.50587936e+04  8.50298115e+03  3.19552437e+03\n",
      "   2.24860878e+03  1.06350351e+03  5.38795324e+02 -4.97164815e+02\n",
      "  -2.07850189e+02 -7.63487088e+02 -2.28475984e+04]\n",
      " [-9.11421717e+02 -5.30098736e+02 -1.25199997e+03 -1.10114114e+03\n",
      "  -2.25692038e+03 -8.78847349e+03  9.38693363e+03  5.24114454e+03\n",
      "   3.24000250e+03  2.39264608e+03  1.94299803e+03  9.98782884e+02\n",
      "   9.17661497e+02  2.78305104e+02 -9.55838807e+03]\n",
      " [-5.28084773e+02 -3.07009989e+02 -7.42631073e+02 -6.50000146e+02\n",
      "  -1.36079565e+03 -7.26466642e+03 -1.18769859e+03  6.56471052e+03\n",
      "   3.19095875e+03  1.78794917e+03  1.59720507e+03  1.15348845e+03\n",
      "   1.10530874e+03  5.88783042e+02 -3.94747880e+03]\n",
      " [-3.78486469e+02 -2.23570135e+02 -5.35625027e+02 -4.71416572e+02\n",
      "  -9.76268455e+02 -5.15644918e+03 -1.90551004e+03 -7.83472607e+01\n",
      "   5.61919472e+03  2.51690556e+03  1.46152303e+03  9.49176085e+02\n",
      "   1.00381940e+03  6.56155746e+02 -2.48111189e+03]\n",
      " [-3.10335048e+02 -1.86591288e+02 -4.39907571e+02 -3.90849076e+02\n",
      "  -7.97953235e+02 -4.17254579e+03 -1.54540540e+03 -9.20659279e+02\n",
      "   3.77983488e+02  5.08985461e+03  2.60884130e+03  1.23340838e+03\n",
      "   9.02129643e+02  5.20819348e+02 -1.96877317e+03]\n",
      " [-2.76514511e+02 -1.68876009e+02 -3.89431984e+02 -3.49568042e+02\n",
      "  -7.10695999e+02 -3.69506429e+03 -1.35678509e+03 -8.19158411e+02\n",
      "  -4.82479765e+02  4.34912371e+02  5.20795297e+03  2.46238213e+03\n",
      "   1.40545251e+03  6.34675106e+02 -1.89680313e+03]\n",
      " [-2.49107982e+02 -1.54239814e+02 -3.48257211e+02 -3.16415118e+02\n",
      "  -6.41292067e+02 -3.32846034e+03 -1.21511871e+03 -7.34608679e+02\n",
      "  -4.34096067e+02 -4.08570071e+02  6.86094449e+02  4.94115570e+03\n",
      "   2.57827729e+03  1.28417441e+03 -1.65955263e+03]\n",
      " [-2.14032216e+02 -1.33335738e+02 -2.99327215e+02 -2.72197184e+02\n",
      "  -5.48709287e+02 -2.84794694e+03 -1.03824950e+03 -6.26803727e+02\n",
      "  -3.69643803e+02 -3.48880904e+02 -2.81023402e+02  6.13418338e+02\n",
      "   5.02704476e+03  2.35521491e+03 -1.01551693e+03]\n",
      " [-1.59037930e+02 -9.83684147e+01 -2.19975910e+02 -1.99480877e+02\n",
      "  -4.09794608e+02 -2.14181441e+03 -7.87537779e+02 -4.76419855e+02\n",
      "  -2.81842604e+02 -2.67336437e+02 -2.16737156e+02 -2.50260208e+02\n",
      "   7.25515382e+02  4.61713880e+03  1.65970628e+02]\n",
      " [-2.18123614e+03 -1.32678788e+03 -2.95284313e+03 -2.65148812e+03\n",
      "  -5.68995145e+03 -3.06093514e+04 -1.15931548e+04 -7.00693100e+03\n",
      "  -4.25628929e+03 -4.06869575e+03 -3.29701812e+03 -3.96040619e+03\n",
      "  -3.00957823e+03 -2.06553276e+03  8.46692605e+04]\n",
      " [-9.78374226e+14 -1.54821711e+15  1.86100559e+14 -1.49505056e+15\n",
      "   8.35869179e+15 -2.51471443e+15  6.15282769e+15  1.01276230e+15\n",
      "   4.04499110e+15 -7.36505705e+15  1.45686980e+15 -6.96482534e+15\n",
      "  -3.49707694e+15  1.67486514e+15  1.47620728e+15]\n",
      " [-3.12144138e+15 -9.59852773e+14  8.33360665e+15  3.09087877e+15\n",
      "   3.13625733e+15  5.18378562e+15  2.07509332e+15  2.97231435e+15\n",
      "  -4.08452349e+15 -1.21717821e+16  7.11214521e+15 -2.54464498e+16\n",
      "   1.53855382e+15  6.56486780e+15  5.77654661e+15]]\n"
     ]
    }
   ],
   "source": [
    "print(lr.w_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try softmax regression on the dataset that doesnt drop the first input bin. Average entropy was higher than the uniform so not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/mlxtend/classifier/softmax_regression.py:99: RuntimeWarning: divide by zero encountered in log\n",
      "  return - np.sum(np.log(output) * (y_target), axis=1)\n",
      "/home/keh4nb/.local/lib/python3.7/site-packages/mlxtend/classifier/softmax_regression.py:99: RuntimeWarning: invalid value encountered in multiply\n",
      "  return - np.sum(np.log(output) * (y_target), axis=1)\n",
      "Iteration: 100/100 | Cost nan | Elapsed: 0:03:33 | ETA: 0:00:00"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "count  80034.000000\n",
      "mean     146.456402\n",
      "std      107.506086\n",
      "min        0.000000\n",
      "25%        1.368835\n",
      "50%      227.225369\n",
      "75%      227.225369\n",
      "max     1000.000000\n"
     ]
    }
   ],
   "source": [
    "#%pip install mlxtend \n",
    "from mlxtend.classifier import SoftmaxRegression\n",
    "\n",
    "lr = SoftmaxRegression(eta=0.01, \n",
    "                       epochs=100, # Passes over the training sets\n",
    "                       minibatches=1, # Gradient descent learning\n",
    "                       l2=0.5, # L2 regularization\n",
    "                       random_seed=1,\n",
    "                       print_progress=3)\n",
    "lr.fit(X_train.to_numpy(), y_train['y'])\n",
    "\n",
    "# Extract probabilities and show entropy\n",
    "probs_softmax = lr.predict_proba(X_test.to_numpy())\n",
    "df_softmax_entropy = pd.DataFrame(get_entropy_from_predictions(y_test, probs_softmax))\n",
    "df_softmax_entropy.replace(np.inf, 1000, inplace=True)\n",
    "\n",
    "# Select a test observation to graph\n",
    "test_obs = probs_softmax[5]\n",
    "cols = [f'Output_Bin_{i}' for i in range(bin_size)]\n",
    "\n",
    "# Get the true distribution\n",
    "y_obs = y_test.iloc[5][cols]\n",
    "\n",
    "# Plot the two together\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(test_obs, color='blue')\n",
    "plt.plot(y_obs, color='orange')\n",
    "plt.show()\n",
    "\n",
    "print(df_softmax_entropy.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
