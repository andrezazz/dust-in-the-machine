{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mdn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.katnoria.com/mdn/ and https://github.com/cpmpercussion/keras-mdn-layer/blob/master/notebooks/MDN-2D-spiral-prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate train and test data (10 dimensional input and otput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.615034</td>\n",
       "      <td>3.267617</td>\n",
       "      <td>4.053592</td>\n",
       "      <td>9.421212</td>\n",
       "      <td>3.954029</td>\n",
       "      <td>4.150867</td>\n",
       "      <td>3.937071</td>\n",
       "      <td>3.510375</td>\n",
       "      <td>4.306158</td>\n",
       "      <td>3.270168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.074900</td>\n",
       "      <td>4.379744</td>\n",
       "      <td>30.411219</td>\n",
       "      <td>190.439178</td>\n",
       "      <td>18.233643</td>\n",
       "      <td>24.917324</td>\n",
       "      <td>14.574010</td>\n",
       "      <td>6.602884</td>\n",
       "      <td>42.716599</td>\n",
       "      <td>3.143604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.931069</td>\n",
       "      <td>1.919399</td>\n",
       "      <td>1.932806</td>\n",
       "      <td>1.926581</td>\n",
       "      <td>1.955224</td>\n",
       "      <td>1.925359</td>\n",
       "      <td>1.930354</td>\n",
       "      <td>1.912630</td>\n",
       "      <td>1.944402</td>\n",
       "      <td>1.924374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.606955</td>\n",
       "      <td>2.601793</td>\n",
       "      <td>2.621750</td>\n",
       "      <td>2.617450</td>\n",
       "      <td>2.620316</td>\n",
       "      <td>2.615520</td>\n",
       "      <td>2.615036</td>\n",
       "      <td>2.606159</td>\n",
       "      <td>2.603743</td>\n",
       "      <td>2.615273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.718506</td>\n",
       "      <td>2.710202</td>\n",
       "      <td>2.723087</td>\n",
       "      <td>2.724280</td>\n",
       "      <td>2.724586</td>\n",
       "      <td>2.722993</td>\n",
       "      <td>2.726348</td>\n",
       "      <td>2.719437</td>\n",
       "      <td>2.713055</td>\n",
       "      <td>2.724423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.943890</td>\n",
       "      <td>2.906171</td>\n",
       "      <td>2.991657</td>\n",
       "      <td>2.943192</td>\n",
       "      <td>2.974401</td>\n",
       "      <td>2.973311</td>\n",
       "      <td>2.943957</td>\n",
       "      <td>2.987256</td>\n",
       "      <td>2.909145</td>\n",
       "      <td>2.971518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>498.316986</td>\n",
       "      <td>108.085106</td>\n",
       "      <td>1354.224121</td>\n",
       "      <td>7471.788574</td>\n",
       "      <td>759.466125</td>\n",
       "      <td>907.086975</td>\n",
       "      <td>554.168762</td>\n",
       "      <td>237.240692</td>\n",
       "      <td>1901.668213</td>\n",
       "      <td>86.301041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      3.615034     3.267617     4.053592     9.421212     3.954029   \n",
       "std      12.074900     4.379744    30.411219   190.439178    18.233643   \n",
       "min       1.931069     1.919399     1.932806     1.926581     1.955224   \n",
       "25%       2.606955     2.601793     2.621750     2.617450     2.620316   \n",
       "50%       2.718506     2.710202     2.723087     2.724280     2.724586   \n",
       "75%       2.943890     2.906171     2.991657     2.943192     2.974401   \n",
       "max     498.316986   108.085106  1354.224121  7471.788574   759.466125   \n",
       "\n",
       "                 5            6            7            8            9  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean      4.150867     3.937071     3.510375     4.306158     3.270168  \n",
       "std      24.917324    14.574010     6.602884    42.716599     3.143604  \n",
       "min       1.925359     1.930354     1.912630     1.944402     1.924374  \n",
       "25%       2.615520     2.615036     2.606159     2.603743     2.615273  \n",
       "50%       2.722993     2.726348     2.719437     2.713055     2.724423  \n",
       "75%       2.973311     2.943957     2.987256     2.909145     2.971518  \n",
       "max     907.086975   554.168762   237.240692  1901.668213    86.301041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_data(n=1000, cols=2):\n",
    "    # sample uniformly over the interval (0,1)\n",
    "    X = np.random.uniform(0., 1., (n,cols)).astype(np.float32)    \n",
    "    # Add 2 to have strictly positive Y\n",
    "    y = 2 + (X + 0.3 * np.sin(2 * np.pi * X) + 0.2 * np.tan(np.pi / 2 * X) + np.random.uniform(-0.1, 0.1, size=(n,cols)).astype(np.float32))\n",
    "    return X,y\n",
    "\n",
    "X,y = gen_data(n=20000, cols=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.10, random_state=42)\n",
    "\n",
    "display(pd.DataFrame(y_test).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our neural network with 1 hidden layer of 256 nodes and 20 mixture density models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cols\n",
    "l = 10\n",
    "# Number of gaussians to represent the multimodal distribution (number of mixture density models)\n",
    "k = 20\n",
    "\n",
    "# Network\n",
    "input = tf.keras.Input(shape=(l,))\n",
    "\n",
    "layer = tf.keras.layers.Dense(256, activation='sigmoid', name='baselayer')(input)\n",
    "#layer_2 = tf.keras.layers.Dense(64, activation='sigmoid', name='baselayer2')(layer)\n",
    "# Connect the mdn layer to the output of our neural network\n",
    "mdn_layer = mdn.MDN(l,k, name='mdn')(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model and display the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "baselayer (Dense)            (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "mdn (MDN)                    (None, 420)               107940    \n",
      "=================================================================\n",
      "Total params: 110,756\n",
      "Trainable params: 110,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Model(input, [mdn_layer])\n",
    "model.compile(loss=mdn.get_mixture_loss_func(l,k), optimizer=tf.keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our model on the data with 300 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 68.3724 - val_loss: 23.1825\n",
      "Epoch 2/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 66.1413 - val_loss: 22.6586\n",
      "Epoch 3/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 64.1613 - val_loss: 22.0307\n",
      "Epoch 4/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 62.1398 - val_loss: 21.5690\n",
      "Epoch 5/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 60.2215 - val_loss: 20.9884\n",
      "Epoch 6/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 58.4726 - val_loss: 20.5177\n",
      "Epoch 7/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 56.7565 - val_loss: 20.0580\n",
      "Epoch 8/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 54.9648 - val_loss: 19.5187\n",
      "Epoch 9/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 53.3679 - val_loss: 19.1614\n",
      "Epoch 10/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 51.7735 - val_loss: 18.8104\n",
      "Epoch 11/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 50.1719 - val_loss: 18.3968\n",
      "Epoch 12/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 48.6999 - val_loss: 17.9826\n",
      "Epoch 13/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 47.3405 - val_loss: 17.6453\n",
      "Epoch 14/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 45.9811 - val_loss: 17.2778\n",
      "Epoch 15/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 44.6821 - val_loss: 16.9690\n",
      "Epoch 16/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 43.4649 - val_loss: 16.4891\n",
      "Epoch 17/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 42.2160 - val_loss: 16.2246\n",
      "Epoch 18/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 41.0025 - val_loss: 15.8878\n",
      "Epoch 19/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 39.9210 - val_loss: 15.7685\n",
      "Epoch 20/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 38.8190 - val_loss: 15.4392\n",
      "Epoch 21/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 37.8139 - val_loss: 15.0464\n",
      "Epoch 22/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 36.7641 - val_loss: 14.6981\n",
      "Epoch 23/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 35.7783 - val_loss: 14.5314\n",
      "Epoch 24/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 34.8239 - val_loss: 14.2850\n",
      "Epoch 25/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 33.9713 - val_loss: 14.0300\n",
      "Epoch 26/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 33.0886 - val_loss: 13.6792\n",
      "Epoch 27/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 32.2274 - val_loss: 13.4345\n",
      "Epoch 28/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 31.4227 - val_loss: 13.2889\n",
      "Epoch 29/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 30.5958 - val_loss: 13.1419\n",
      "Epoch 30/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 29.8224 - val_loss: 12.8440\n",
      "Epoch 31/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 29.0446 - val_loss: 12.6956\n",
      "Epoch 32/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 28.3381 - val_loss: 12.2950\n",
      "Epoch 33/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 27.7265 - val_loss: 12.1258\n",
      "Epoch 34/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 26.9847 - val_loss: 11.8806\n",
      "Epoch 35/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 26.3755 - val_loss: 11.9036\n",
      "Epoch 36/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 25.6783 - val_loss: 11.5903\n",
      "Epoch 37/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 25.0151 - val_loss: 11.3011\n",
      "Epoch 38/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 24.4885 - val_loss: 11.2524\n",
      "Epoch 39/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 23.8857 - val_loss: 11.1185\n",
      "Epoch 40/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 23.2730 - val_loss: 10.9166\n",
      "Epoch 41/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 22.7396 - val_loss: 10.6594\n",
      "Epoch 42/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 22.2851 - val_loss: 10.5502\n",
      "Epoch 43/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 21.7019 - val_loss: 10.1428\n",
      "Epoch 44/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 21.1271 - val_loss: 10.1222\n",
      "Epoch 45/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 20.6906 - val_loss: 10.1598\n",
      "Epoch 46/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 20.1555 - val_loss: 9.8819\n",
      "Epoch 47/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 19.6607 - val_loss: 9.4857\n",
      "Epoch 48/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 19.2485 - val_loss: 9.3439\n",
      "Epoch 49/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 18.8899 - val_loss: 9.3425\n",
      "Epoch 50/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 18.4305 - val_loss: 9.2249\n",
      "Epoch 51/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 18.0347 - val_loss: 9.0326\n",
      "Epoch 52/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 17.6420 - val_loss: 8.8501\n",
      "Epoch 53/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 17.3009 - val_loss: 8.7226\n",
      "Epoch 54/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 16.8043 - val_loss: 8.5216\n",
      "Epoch 55/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 16.4908 - val_loss: 8.5152\n",
      "Epoch 56/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 16.0770 - val_loss: 8.3700\n",
      "Epoch 57/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 15.7558 - val_loss: 8.3287\n",
      "Epoch 58/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 15.3906 - val_loss: 8.2095\n",
      "Epoch 59/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 15.0866 - val_loss: 7.9446\n",
      "Epoch 60/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 14.7470 - val_loss: 7.7875\n",
      "Epoch 61/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 14.4354 - val_loss: 7.7964\n",
      "Epoch 62/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 14.1719 - val_loss: 7.6575\n",
      "Epoch 63/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 13.8424 - val_loss: 7.7487\n",
      "Epoch 64/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 13.6369 - val_loss: 7.5835\n",
      "Epoch 65/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 13.3454 - val_loss: 7.2770\n",
      "Epoch 66/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 13.1117 - val_loss: 7.4096\n",
      "Epoch 67/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 12.9248 - val_loss: 7.2720\n",
      "Epoch 68/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 12.6475 - val_loss: 7.2815\n",
      "Epoch 69/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 12.4907 - val_loss: 7.1430\n",
      "Epoch 70/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 12.3058 - val_loss: 7.0814\n",
      "Epoch 71/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.9338 - val_loss: 6.9167\n",
      "Epoch 72/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.8387 - val_loss: 6.9097\n",
      "Epoch 73/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.6590 - val_loss: 6.8429\n",
      "Epoch 74/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.4906 - val_loss: 6.5822\n",
      "Epoch 75/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.1193 - val_loss: 6.7174\n",
      "Epoch 76/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 11.0663 - val_loss: 6.7231\n",
      "Epoch 77/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.8601 - val_loss: 6.8200\n",
      "Epoch 78/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.7104 - val_loss: 6.9542\n",
      "Epoch 79/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.5842 - val_loss: 6.5022\n",
      "Epoch 80/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.3822 - val_loss: 6.6768\n",
      "Epoch 81/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.2759 - val_loss: 6.5887\n",
      "Epoch 82/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 10.1022 - val_loss: 6.5344\n",
      "Epoch 83/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.8888 - val_loss: 6.7673\n",
      "Epoch 84/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.8105 - val_loss: 6.6031\n",
      "Epoch 85/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.7524 - val_loss: 6.4200\n",
      "Epoch 86/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.6013 - val_loss: 6.4628\n",
      "Epoch 87/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.4277 - val_loss: 6.4327\n",
      "Epoch 88/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.3263 - val_loss: 6.2020\n",
      "Epoch 89/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.0825 - val_loss: 6.2470\n",
      "Epoch 90/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 9.1443 - val_loss: 6.2548\n",
      "Epoch 91/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.9201 - val_loss: 6.0924\n",
      "Epoch 92/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.8941 - val_loss: 6.3784\n",
      "Epoch 93/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.7870 - val_loss: 6.1559\n",
      "Epoch 94/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.6651 - val_loss: 6.2988\n",
      "Epoch 95/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.5587 - val_loss: 5.9505\n",
      "Epoch 96/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.3921 - val_loss: 5.9781\n",
      "Epoch 97/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.3710 - val_loss: 6.1508\n",
      "Epoch 98/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.2331 - val_loss: 6.0457\n",
      "Epoch 99/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.1911 - val_loss: 6.0576\n",
      "Epoch 100/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.1226 - val_loss: 5.9431\n",
      "Epoch 101/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 8.0520 - val_loss: 5.9918\n",
      "Epoch 102/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.9611 - val_loss: 6.1539\n",
      "Epoch 103/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.8408 - val_loss: 5.8552\n",
      "Epoch 104/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.8118 - val_loss: 5.9139\n",
      "Epoch 105/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.6377 - val_loss: 5.9161\n",
      "Epoch 106/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.5767 - val_loss: 5.7999\n",
      "Epoch 107/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 7.4565 - val_loss: 5.7150\n",
      "Epoch 108/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 7.4966 - val_loss: 5.8316\n",
      "Epoch 109/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.4569 - val_loss: 5.6245\n",
      "Epoch 110/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.3306 - val_loss: 5.8616\n",
      "Epoch 111/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.2560 - val_loss: 5.6131\n",
      "Epoch 112/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.2375 - val_loss: 6.0414\n",
      "Epoch 113/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.2066 - val_loss: 6.0407\n",
      "Epoch 114/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 7.1506 - val_loss: 5.7126\n",
      "Epoch 115/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.9697 - val_loss: 5.6228\n",
      "Epoch 116/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.9355 - val_loss: 5.6591\n",
      "Epoch 117/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.8613 - val_loss: 5.7434\n",
      "Epoch 118/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.7780 - val_loss: 5.9472\n",
      "Epoch 119/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.8585 - val_loss: 5.9122\n",
      "Epoch 120/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.7555 - val_loss: 5.7547\n",
      "Epoch 121/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.6168 - val_loss: 5.7223\n",
      "Epoch 122/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.7083 - val_loss: 5.6722\n",
      "Epoch 123/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.5612 - val_loss: 5.8943\n",
      "Epoch 124/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.5426 - val_loss: 5.6815\n",
      "Epoch 125/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.5151 - val_loss: 5.7080\n",
      "Epoch 126/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.4307 - val_loss: 5.6765\n",
      "Epoch 127/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.4320 - val_loss: 5.5462\n",
      "Epoch 128/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.4440 - val_loss: 5.6229\n",
      "Epoch 129/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.3038 - val_loss: 5.5302\n",
      "Epoch 130/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.2785 - val_loss: 5.7212\n",
      "Epoch 131/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.1828 - val_loss: 5.5531\n",
      "Epoch 132/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 6.2388 - val_loss: 5.7266\n",
      "Epoch 133/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.1937 - val_loss: 5.4638\n",
      "Epoch 134/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.1469 - val_loss: 5.5257\n",
      "Epoch 135/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.9858 - val_loss: 5.4159\n",
      "Epoch 136/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.9998 - val_loss: 5.6398\n",
      "Epoch 137/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.0759 - val_loss: 5.6026\n",
      "Epoch 138/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.0368 - val_loss: 5.7550\n",
      "Epoch 139/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 6.0012 - val_loss: 5.7069\n",
      "Epoch 140/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.8930 - val_loss: 5.6124\n",
      "Epoch 141/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.8253 - val_loss: 5.7057\n",
      "Epoch 142/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.8261 - val_loss: 5.7689\n",
      "Epoch 143/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.8280 - val_loss: 5.4530\n",
      "Epoch 144/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.7932 - val_loss: 5.8265\n",
      "Epoch 145/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.7836 - val_loss: 6.0170\n",
      "Epoch 146/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.8507 - val_loss: 5.5432\n",
      "Epoch 147/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.7449 - val_loss: 5.5630\n",
      "Epoch 148/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.6990 - val_loss: 5.6148\n",
      "Epoch 149/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.6694 - val_loss: 5.5009\n",
      "Epoch 150/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.6126 - val_loss: 5.3894\n",
      "Epoch 151/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.5834 - val_loss: 5.7022\n",
      "Epoch 152/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.5643 - val_loss: 5.5009\n",
      "Epoch 153/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.4471 - val_loss: 5.4259\n",
      "Epoch 154/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.4387 - val_loss: 5.5477\n",
      "Epoch 155/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.5002 - val_loss: 5.6014\n",
      "Epoch 156/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.5028 - val_loss: 5.7130\n",
      "Epoch 157/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.4268 - val_loss: 5.5629\n",
      "Epoch 158/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.5136 - val_loss: 5.7473\n",
      "Epoch 159/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.4352 - val_loss: 5.7438\n",
      "Epoch 160/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.3639 - val_loss: 5.5024\n",
      "Epoch 161/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2899 - val_loss: 5.8095\n",
      "Epoch 162/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.3249 - val_loss: 5.4967\n",
      "Epoch 163/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.3053 - val_loss: 5.5811\n",
      "Epoch 164/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.3033 - val_loss: 5.5880\n",
      "Epoch 165/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2826 - val_loss: 5.5380\n",
      "Epoch 166/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.1959 - val_loss: 5.6299\n",
      "Epoch 167/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2757 - val_loss: 5.6889\n",
      "Epoch 168/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2387 - val_loss: 5.3223\n",
      "Epoch 169/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.1059 - val_loss: 5.4602\n",
      "Epoch 170/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.1708 - val_loss: 5.5827\n",
      "Epoch 171/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.1886 - val_loss: 5.9250\n",
      "Epoch 172/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.1191 - val_loss: 5.5857\n",
      "Epoch 173/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.1488 - val_loss: 5.5443\n",
      "Epoch 174/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.1805 - val_loss: 5.7020\n",
      "Epoch 175/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.0932 - val_loss: 5.5849\n",
      "Epoch 176/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.0970 - val_loss: 5.5091\n",
      "Epoch 177/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.0561 - val_loss: 5.3180\n",
      "Epoch 178/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9776 - val_loss: 5.6061\n",
      "Epoch 179/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.1151 - val_loss: 5.4988\n",
      "Epoch 180/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.9800 - val_loss: 5.5166\n",
      "Epoch 181/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.0056 - val_loss: 5.7069\n",
      "Epoch 182/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.9640 - val_loss: 5.2545\n",
      "Epoch 183/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9295 - val_loss: 5.4844\n",
      "Epoch 184/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.0001 - val_loss: 5.4264\n",
      "Epoch 185/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9566 - val_loss: 5.6474\n",
      "Epoch 186/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8775 - val_loss: 5.2860\n",
      "Epoch 187/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9459 - val_loss: 5.5075\n",
      "Epoch 188/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.0778 - val_loss: 5.6467\n",
      "Epoch 189/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9462 - val_loss: 5.5424\n",
      "Epoch 190/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8641 - val_loss: 5.3410\n",
      "Epoch 191/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8337 - val_loss: 5.3365\n",
      "Epoch 192/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.9276 - val_loss: 5.4517\n",
      "Epoch 193/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8764 - val_loss: 5.4128\n",
      "Epoch 194/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8211 - val_loss: 5.6997\n",
      "Epoch 195/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.8768 - val_loss: 5.3053\n",
      "Epoch 196/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7683 - val_loss: 5.3223\n",
      "Epoch 197/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7923 - val_loss: 5.4670\n",
      "Epoch 198/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7242 - val_loss: 5.2286\n",
      "Epoch 199/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7456 - val_loss: 5.5041\n",
      "Epoch 200/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7847 - val_loss: 5.2319\n",
      "Epoch 201/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7709 - val_loss: 5.5966\n",
      "Epoch 202/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7588 - val_loss: 5.3975\n",
      "Epoch 203/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6925 - val_loss: 5.4394\n",
      "Epoch 204/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6972 - val_loss: 5.4491\n",
      "Epoch 205/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6669 - val_loss: 5.5228\n",
      "Epoch 206/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.7057 - val_loss: 5.3402\n",
      "Epoch 207/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5848 - val_loss: 5.4404\n",
      "Epoch 208/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6905 - val_loss: 5.4008\n",
      "Epoch 209/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6580 - val_loss: 5.6216\n",
      "Epoch 210/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.7273 - val_loss: 5.1899\n",
      "Epoch 211/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6380 - val_loss: 5.4272\n",
      "Epoch 212/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6694 - val_loss: 5.4181\n",
      "Epoch 213/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6934 - val_loss: 5.1914\n",
      "Epoch 214/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5912 - val_loss: 5.3466\n",
      "Epoch 215/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5791 - val_loss: 5.1614\n",
      "Epoch 216/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.6489 - val_loss: 5.3528\n",
      "Epoch 217/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.6615 - val_loss: 5.4622\n",
      "Epoch 218/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.6099 - val_loss: 5.1686\n",
      "Epoch 219/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.5772 - val_loss: 5.7387\n",
      "Epoch 220/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.5818 - val_loss: 5.4342\n",
      "Epoch 221/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4586 - val_loss: 5.2664\n",
      "Epoch 222/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5451 - val_loss: 5.2008\n",
      "Epoch 223/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5240 - val_loss: 5.9039\n",
      "Epoch 224/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5680 - val_loss: 5.3005\n",
      "Epoch 225/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5454 - val_loss: 5.1635\n",
      "Epoch 226/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4210 - val_loss: 5.3284\n",
      "Epoch 227/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4644 - val_loss: 5.4089\n",
      "Epoch 228/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5279 - val_loss: 4.9772\n",
      "Epoch 229/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4294 - val_loss: 5.2327\n",
      "Epoch 230/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4795 - val_loss: 5.4288\n",
      "Epoch 231/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4558 - val_loss: 5.3489\n",
      "Epoch 232/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4635 - val_loss: 5.3405\n",
      "Epoch 233/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.4370 - val_loss: 5.1802\n",
      "Epoch 234/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3776 - val_loss: 5.3128\n",
      "Epoch 235/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.5058 - val_loss: 5.3446\n",
      "Epoch 236/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3876 - val_loss: 5.2746\n",
      "Epoch 237/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3486 - val_loss: 5.1129\n",
      "Epoch 238/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3221 - val_loss: 5.2254\n",
      "Epoch 239/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3704 - val_loss: 5.1245\n",
      "Epoch 240/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.3757 - val_loss: 5.4594\n",
      "Epoch 241/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 4.4256 - val_loss: 5.2469\n",
      "Epoch 242/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.3713 - val_loss: 5.1459\n",
      "Epoch 243/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3775 - val_loss: 5.1531\n",
      "Epoch 244/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3350 - val_loss: 5.3855\n",
      "Epoch 245/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3233 - val_loss: 5.4877\n",
      "Epoch 246/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3583 - val_loss: 5.4131\n",
      "Epoch 247/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3648 - val_loss: 5.1931\n",
      "Epoch 248/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3582 - val_loss: 5.3626\n",
      "Epoch 249/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3721 - val_loss: 5.3881\n",
      "Epoch 250/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2657 - val_loss: 5.2217\n",
      "Epoch 251/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2535 - val_loss: 5.2768\n",
      "Epoch 252/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.2833 - val_loss: 5.4133\n",
      "Epoch 253/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.3122 - val_loss: 5.9361\n",
      "Epoch 254/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2551 - val_loss: 5.2675\n",
      "Epoch 255/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2444 - val_loss: 5.6442\n",
      "Epoch 256/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2909 - val_loss: 5.5182\n",
      "Epoch 257/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2370 - val_loss: 5.3265\n",
      "Epoch 258/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2156 - val_loss: 5.0451\n",
      "Epoch 259/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.2026 - val_loss: 5.3474\n",
      "Epoch 260/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1855 - val_loss: 5.0843\n",
      "Epoch 261/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1582 - val_loss: 5.1524\n",
      "Epoch 262/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1721 - val_loss: 5.1140\n",
      "Epoch 263/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1925 - val_loss: 5.1182\n",
      "Epoch 264/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 4.1781 - val_loss: 5.1709\n",
      "Epoch 265/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1647 - val_loss: 5.3589\n",
      "Epoch 266/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1881 - val_loss: 5.2832\n",
      "Epoch 267/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1838 - val_loss: 5.1443\n",
      "Epoch 268/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0902 - val_loss: 4.9915\n",
      "Epoch 269/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1567 - val_loss: 5.0553\n",
      "Epoch 270/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0837 - val_loss: 5.2830\n",
      "Epoch 271/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1007 - val_loss: 4.9304\n",
      "Epoch 272/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1353 - val_loss: 5.1468\n",
      "Epoch 273/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0622 - val_loss: 5.1558\n",
      "Epoch 274/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0587 - val_loss: 5.3408\n",
      "Epoch 275/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1420 - val_loss: 5.2373\n",
      "Epoch 276/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.1120 - val_loss: 5.1487\n",
      "Epoch 277/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0953 - val_loss: 5.0422\n",
      "Epoch 278/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0469 - val_loss: 5.1370\n",
      "Epoch 279/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9806 - val_loss: 5.3644\n",
      "Epoch 280/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0494 - val_loss: 5.0542\n",
      "Epoch 281/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9459 - val_loss: 5.0377\n",
      "Epoch 282/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9387 - val_loss: 4.9204\n",
      "Epoch 283/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0504 - val_loss: 4.9865\n",
      "Epoch 284/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 4.0405 - val_loss: 5.1169\n",
      "Epoch 285/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9761 - val_loss: 5.0056\n",
      "Epoch 286/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9176 - val_loss: 4.8141\n",
      "Epoch 287/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9253 - val_loss: 5.3188\n",
      "Epoch 288/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.9820 - val_loss: 4.8784\n",
      "Epoch 289/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 3.8361 - val_loss: 4.9515\n",
      "Epoch 290/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 3.7954 - val_loss: 5.0282\n",
      "Epoch 291/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.8613 - val_loss: 4.8799\n",
      "Epoch 292/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.8963 - val_loss: 4.9040\n",
      "Epoch 293/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.8655 - val_loss: 4.9356\n",
      "Epoch 294/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.8350 - val_loss: 5.0422\n",
      "Epoch 295/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7999 - val_loss: 5.1663\n",
      "Epoch 296/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7909 - val_loss: 4.8931\n",
      "Epoch 297/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.6695 - val_loss: 4.8666\n",
      "Epoch 298/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7971 - val_loss: 4.9482\n",
      "Epoch 299/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.6983 - val_loss: 4.7683\n",
      "Epoch 300/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.6872 - val_loss: 4.4729\n",
      "Epoch 301/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7048 - val_loss: 4.7512\n",
      "Epoch 302/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7189 - val_loss: 4.6935\n",
      "Epoch 303/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7564 - val_loss: 5.0635\n",
      "Epoch 304/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7129 - val_loss: 4.8040\n",
      "Epoch 305/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.6620 - val_loss: 4.9340\n",
      "Epoch 306/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.5989 - val_loss: 4.5717\n",
      "Epoch 307/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.7304 - val_loss: 5.2815\n",
      "Epoch 308/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.6384 - val_loss: 5.0325\n",
      "Epoch 309/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.5682 - val_loss: 4.5661\n",
      "Epoch 310/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.5598 - val_loss: 4.7289\n",
      "Epoch 311/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.5346 - val_loss: 4.5915\n",
      "Epoch 312/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.5563 - val_loss: 4.7360\n",
      "Epoch 313/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.4814 - val_loss: 4.4468\n",
      "Epoch 314/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 3.4411 - val_loss: 4.6094\n",
      "Epoch 315/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3569 - val_loss: 4.5025\n",
      "Epoch 316/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.4769 - val_loss: 4.3226\n",
      "Epoch 317/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.4045 - val_loss: 4.6743\n",
      "Epoch 318/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.4250 - val_loss: 4.6054\n",
      "Epoch 319/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3741 - val_loss: 4.5889\n",
      "Epoch 320/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3834 - val_loss: 4.4345\n",
      "Epoch 321/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3773 - val_loss: 4.4914\n",
      "Epoch 322/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3685 - val_loss: 4.5969\n",
      "Epoch 323/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3488 - val_loss: 4.5965\n",
      "Epoch 324/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2527 - val_loss: 4.4099\n",
      "Epoch 325/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2942 - val_loss: 4.7204\n",
      "Epoch 326/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.3618 - val_loss: 4.3438\n",
      "Epoch 327/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2185 - val_loss: 4.3278\n",
      "Epoch 328/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2869 - val_loss: 4.8168\n",
      "Epoch 329/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2361 - val_loss: 4.1985\n",
      "Epoch 330/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.1353 - val_loss: 4.6805\n",
      "Epoch 331/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.2212 - val_loss: 4.3067\n",
      "Epoch 332/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0589 - val_loss: 4.2375\n",
      "Epoch 333/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0354 - val_loss: 4.0743\n",
      "Epoch 334/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0760 - val_loss: 4.1267\n",
      "Epoch 335/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.9852 - val_loss: 4.4503\n",
      "Epoch 336/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0876 - val_loss: 4.4002\n",
      "Epoch 337/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0618 - val_loss: 4.1948\n",
      "Epoch 338/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 3.0630 - val_loss: 4.1439\n",
      "Epoch 339/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.9515 - val_loss: 4.1178\n",
      "Epoch 340/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.9598 - val_loss: 4.1034\n",
      "Epoch 341/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8905 - val_loss: 3.9156\n",
      "Epoch 342/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8687 - val_loss: 3.9767\n",
      "Epoch 343/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8390 - val_loss: 3.8861\n",
      "Epoch 344/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8277 - val_loss: 3.8779\n",
      "Epoch 345/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8738 - val_loss: 3.9528\n",
      "Epoch 346/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7847 - val_loss: 4.1455\n",
      "Epoch 347/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.8434 - val_loss: 3.9715\n",
      "Epoch 348/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7658 - val_loss: 4.1036\n",
      "Epoch 349/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7685 - val_loss: 3.9611\n",
      "Epoch 350/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.6955 - val_loss: 3.9542\n",
      "Epoch 351/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7223 - val_loss: 3.8790\n",
      "Epoch 352/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7689 - val_loss: 3.8784\n",
      "Epoch 353/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.7120 - val_loss: 3.8323\n",
      "Epoch 354/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.6263 - val_loss: 3.9681\n",
      "Epoch 355/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.6563 - val_loss: 3.7371\n",
      "Epoch 356/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.6259 - val_loss: 3.8193\n",
      "Epoch 357/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.5999 - val_loss: 3.9187\n",
      "Epoch 358/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.5522 - val_loss: 3.5961\n",
      "Epoch 359/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.6112 - val_loss: 3.8173\n",
      "Epoch 360/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 2.6096 - val_loss: 3.8310\n",
      "Epoch 361/1000\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 2.5038 - val_loss: 3.5542\n",
      "Epoch 362/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 2.4515 - val_loss: 3.5608\n",
      "Epoch 363/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4503 - val_loss: 3.5872\n",
      "Epoch 364/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4620 - val_loss: 3.5242\n",
      "Epoch 365/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4985 - val_loss: 3.7024\n",
      "Epoch 366/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4709 - val_loss: 3.8261\n",
      "Epoch 367/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4060 - val_loss: 3.3201\n",
      "Epoch 368/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.3467 - val_loss: 3.6248\n",
      "Epoch 369/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4225 - val_loss: 3.8546\n",
      "Epoch 370/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.4329 - val_loss: 3.3968\n",
      "Epoch 371/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.2893 - val_loss: 3.3205\n",
      "Epoch 372/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.3088 - val_loss: 3.3541\n",
      "Epoch 373/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.3230 - val_loss: 3.5782\n",
      "Epoch 374/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.2804 - val_loss: 3.8553\n",
      "Epoch 375/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.2281 - val_loss: 3.3423\n",
      "Epoch 376/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.2380 - val_loss: 3.2304\n",
      "Epoch 377/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.1634 - val_loss: 3.4603\n",
      "Epoch 378/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.2451 - val_loss: 3.4361\n",
      "Epoch 379/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.1757 - val_loss: 3.6214\n",
      "Epoch 380/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.1907 - val_loss: 3.2442\n",
      "Epoch 381/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.0690 - val_loss: 3.4859\n",
      "Epoch 382/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.1294 - val_loss: 3.3761\n",
      "Epoch 383/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.0072 - val_loss: 3.1488\n",
      "Epoch 384/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.1720 - val_loss: 3.5616\n",
      "Epoch 385/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 2.0143 - val_loss: 3.3351\n",
      "Epoch 386/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9626 - val_loss: 3.1149\n",
      "Epoch 387/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 1.9812 - val_loss: 3.0952\n",
      "Epoch 388/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9411 - val_loss: 2.9808\n",
      "Epoch 389/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 1.9124 - val_loss: 2.9680\n",
      "Epoch 390/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9224 - val_loss: 3.1791\n",
      "Epoch 391/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9848 - val_loss: 3.5532\n",
      "Epoch 392/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9529 - val_loss: 3.3171\n",
      "Epoch 393/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9642 - val_loss: 3.0880\n",
      "Epoch 394/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.8989 - val_loss: 2.9817\n",
      "Epoch 395/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.8966 - val_loss: 2.6114\n",
      "Epoch 396/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.8579 - val_loss: 3.0615\n",
      "Epoch 397/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.9022 - val_loss: 2.9490\n",
      "Epoch 398/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 3.3811\n",
      "Epoch 399/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 1.8087 - val_loss: 3.1157\n",
      "Epoch 400/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 1.7617 - val_loss: 2.8622\n",
      "Epoch 401/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 1.6804 - val_loss: 2.8929\n",
      "Epoch 402/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 1.8211 - val_loss: 2.8225\n",
      "Epoch 403/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6683 - val_loss: 2.9305\n",
      "Epoch 404/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.7034 - val_loss: 2.8794\n",
      "Epoch 405/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6697 - val_loss: 2.8296\n",
      "Epoch 406/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6568 - val_loss: 2.8844\n",
      "Epoch 407/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6480 - val_loss: 2.6317\n",
      "Epoch 408/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6768 - val_loss: 3.0884\n",
      "Epoch 409/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6108 - val_loss: 2.6392\n",
      "Epoch 410/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5821 - val_loss: 2.7944\n",
      "Epoch 411/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.6949 - val_loss: 2.7108\n",
      "Epoch 412/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5557 - val_loss: 2.9702\n",
      "Epoch 413/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5646 - val_loss: 2.6553\n",
      "Epoch 414/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5266 - val_loss: 2.9801\n",
      "Epoch 415/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5538 - val_loss: 3.0657\n",
      "Epoch 416/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5467 - val_loss: 2.7300\n",
      "Epoch 417/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.5237 - val_loss: 2.6616\n",
      "Epoch 418/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.4481 - val_loss: 2.6629\n",
      "Epoch 419/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.4991 - val_loss: 2.5981\n",
      "Epoch 420/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.3806 - val_loss: 2.5044\n",
      "Epoch 421/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.3661 - val_loss: 2.5556\n",
      "Epoch 422/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.4267 - val_loss: 2.4008\n",
      "Epoch 423/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.3521 - val_loss: 2.5299\n",
      "Epoch 424/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2809 - val_loss: 2.3126\n",
      "Epoch 425/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2349 - val_loss: 2.2850\n",
      "Epoch 426/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2912 - val_loss: 2.3888\n",
      "Epoch 427/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2464 - val_loss: 2.3285\n",
      "Epoch 428/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.3328 - val_loss: 2.3423\n",
      "Epoch 429/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2310 - val_loss: 2.1305\n",
      "Epoch 430/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1851 - val_loss: 2.4367\n",
      "Epoch 431/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1992 - val_loss: 2.2438\n",
      "Epoch 432/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.2644 - val_loss: 2.3956\n",
      "Epoch 433/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1108 - val_loss: 2.2560\n",
      "Epoch 434/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1134 - val_loss: 2.3816\n",
      "Epoch 435/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1197 - val_loss: 2.2008\n",
      "Epoch 436/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.0028 - val_loss: 2.1989\n",
      "Epoch 437/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.1681 - val_loss: 2.6361\n",
      "Epoch 438/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.0410 - val_loss: 2.3157\n",
      "Epoch 439/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.0299 - val_loss: 2.0061\n",
      "Epoch 440/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 2.1992\n",
      "Epoch 441/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 1.0088 - val_loss: 2.3685\n",
      "Epoch 442/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9960 - val_loss: 2.4654\n",
      "Epoch 443/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 1.9722\n",
      "Epoch 444/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9256 - val_loss: 2.0018\n",
      "Epoch 445/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 2.1035\n",
      "Epoch 446/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9073 - val_loss: 2.2370\n",
      "Epoch 447/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.8351 - val_loss: 1.8366\n",
      "Epoch 448/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.7145 - val_loss: 2.1730\n",
      "Epoch 449/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9411 - val_loss: 1.7344\n",
      "Epoch 450/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.9034 - val_loss: 2.1181\n",
      "Epoch 451/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.8597 - val_loss: 2.1907\n",
      "Epoch 452/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.7899 - val_loss: 1.8158\n",
      "Epoch 453/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.8357 - val_loss: 1.9327\n",
      "Epoch 454/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6443 - val_loss: 1.9673\n",
      "Epoch 455/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6354 - val_loss: 1.6131\n",
      "Epoch 456/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6580 - val_loss: 2.0452\n",
      "Epoch 457/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.8915 - val_loss: 1.8397\n",
      "Epoch 458/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6489 - val_loss: 2.0200\n",
      "Epoch 459/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6886 - val_loss: 1.8384\n",
      "Epoch 460/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6661 - val_loss: 2.2956\n",
      "Epoch 461/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 1.9135\n",
      "Epoch 462/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5526 - val_loss: 1.8078\n",
      "Epoch 463/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6263 - val_loss: 1.7325\n",
      "Epoch 464/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6100 - val_loss: 1.7530\n",
      "Epoch 465/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5612 - val_loss: 2.3204\n",
      "Epoch 466/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5751 - val_loss: 1.5119\n",
      "Epoch 467/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5610 - val_loss: 1.6779\n",
      "Epoch 468/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5197 - val_loss: 1.6822\n",
      "Epoch 469/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5115 - val_loss: 2.0933\n",
      "Epoch 470/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5244 - val_loss: 1.6873\n",
      "Epoch 471/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3347 - val_loss: 1.5701\n",
      "Epoch 472/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4594 - val_loss: 1.4940\n",
      "Epoch 473/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.4675 - val_loss: 1.4204\n",
      "Epoch 474/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2943 - val_loss: 1.3844\n",
      "Epoch 475/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3391 - val_loss: 1.9171\n",
      "Epoch 476/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 1.5980\n",
      "Epoch 477/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2914 - val_loss: 1.3160\n",
      "Epoch 478/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 1.3442\n",
      "Epoch 479/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2710 - val_loss: 1.2171\n",
      "Epoch 480/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2610 - val_loss: 1.3988\n",
      "Epoch 481/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2451 - val_loss: 1.2264\n",
      "Epoch 482/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 1.0898\n",
      "Epoch 483/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 1.1023\n",
      "Epoch 484/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.2391 - val_loss: 1.5535\n",
      "Epoch 485/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.3034 - val_loss: 1.6802\n",
      "Epoch 486/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 1.1691\n",
      "Epoch 487/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 1.2370\n",
      "Epoch 488/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0611 - val_loss: 1.0134\n",
      "Epoch 489/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0712 - val_loss: 1.3527\n",
      "Epoch 490/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 1.0263\n",
      "Epoch 491/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0300 - val_loss: 1.0318\n",
      "Epoch 492/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 1.2642\n",
      "Epoch 493/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 1.1414\n",
      "Epoch 494/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0130 - val_loss: 1.2994\n",
      "Epoch 495/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0814 - val_loss: 0.7870\n",
      "Epoch 496/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0652 - val_loss: 1.3175\n",
      "Epoch 497/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0661 - val_loss: 1.2612\n",
      "Epoch 498/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1467 - val_loss: 1.0997\n",
      "Epoch 499/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0858 - val_loss: 1.0573\n",
      "Epoch 500/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.0877 - val_loss: 0.8149\n",
      "Epoch 501/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1915 - val_loss: 1.2894\n",
      "Epoch 502/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1655 - val_loss: 0.9317\n",
      "Epoch 503/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1105 - val_loss: 1.3211\n",
      "Epoch 504/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1041 - val_loss: 0.7813\n",
      "Epoch 505/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.2734 - val_loss: 0.9785\n",
      "Epoch 506/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.1473 - val_loss: 1.0049\n",
      "Epoch 507/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.2926 - val_loss: 1.2478\n",
      "Epoch 508/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.2337 - val_loss: 0.9864\n",
      "Epoch 509/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.2995 - val_loss: 1.1534\n",
      "Epoch 510/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.2238 - val_loss: 0.7817\n",
      "Epoch 511/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -0.2990 - val_loss: 1.0313\n",
      "Epoch 512/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.2686 - val_loss: 0.9852\n",
      "Epoch 513/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.1201 - val_loss: 1.0842\n",
      "Epoch 514/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4149 - val_loss: 1.1662\n",
      "Epoch 515/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.3610 - val_loss: 0.8962\n",
      "Epoch 516/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.2760 - val_loss: 0.9384\n",
      "Epoch 517/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4300 - val_loss: 0.7889\n",
      "Epoch 518/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4403 - val_loss: 1.1296\n",
      "Epoch 519/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4903 - val_loss: 0.5935\n",
      "Epoch 520/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4240 - val_loss: 0.7039\n",
      "Epoch 521/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4067 - val_loss: 0.4390\n",
      "Epoch 522/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4183 - val_loss: 0.8286\n",
      "Epoch 523/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.5717 - val_loss: 0.4688\n",
      "Epoch 524/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4796 - val_loss: 0.8715\n",
      "Epoch 525/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.4705 - val_loss: 0.2862\n",
      "Epoch 526/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.6056 - val_loss: 0.8145\n",
      "Epoch 527/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.5700 - val_loss: 0.6244\n",
      "Epoch 528/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.5868 - val_loss: 0.4951\n",
      "Epoch 529/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.5965 - val_loss: 0.3819\n",
      "Epoch 530/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.6187 - val_loss: 0.7364\n",
      "Epoch 531/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.6638 - val_loss: 0.5365\n",
      "Epoch 532/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.5739 - val_loss: 0.6062\n",
      "Epoch 533/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7191 - val_loss: 0.4270\n",
      "Epoch 534/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.6823 - val_loss: 0.6009\n",
      "Epoch 535/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7032 - val_loss: 0.6285\n",
      "Epoch 536/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.6116 - val_loss: 0.7453\n",
      "Epoch 537/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7791 - val_loss: 0.4906\n",
      "Epoch 538/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7611 - val_loss: 0.2927\n",
      "Epoch 539/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8194 - val_loss: 0.5747\n",
      "Epoch 540/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8825 - val_loss: 0.3941\n",
      "Epoch 541/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7753 - val_loss: 0.5256\n",
      "Epoch 542/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7398 - val_loss: 0.3452\n",
      "Epoch 543/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7593 - val_loss: 0.4076\n",
      "Epoch 544/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8745 - val_loss: 0.5295\n",
      "Epoch 545/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7894 - val_loss: 0.8183\n",
      "Epoch 546/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8285 - val_loss: 0.3143\n",
      "Epoch 547/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9019 - val_loss: 0.4804\n",
      "Epoch 548/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8305 - val_loss: 0.3641\n",
      "Epoch 549/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7940 - val_loss: 0.0896\n",
      "Epoch 550/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9874 - val_loss: 0.4372\n",
      "Epoch 551/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8507 - val_loss: 0.3313\n",
      "Epoch 552/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9757 - val_loss: 0.1541\n",
      "Epoch 553/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.8440 - val_loss: 0.5283\n",
      "Epoch 554/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.7795 - val_loss: 0.1370\n",
      "Epoch 555/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9257 - val_loss: 0.3648\n",
      "Epoch 556/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9754 - val_loss: 0.1239\n",
      "Epoch 557/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0045 - val_loss: 0.3271\n",
      "Epoch 558/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9780 - val_loss: 0.4969\n",
      "Epoch 559/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.8972 - val_loss: 0.1898\n",
      "Epoch 560/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.9864 - val_loss: 0.2497\n",
      "Epoch 561/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -1.0293 - val_loss: 0.3707\n",
      "Epoch 562/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -0.9523 - val_loss: -0.1237\n",
      "Epoch 563/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0563 - val_loss: 0.1725\n",
      "Epoch 564/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0284 - val_loss: 0.0527\n",
      "Epoch 565/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -0.9666 - val_loss: -0.0077\n",
      "Epoch 566/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0392 - val_loss: 0.1698\n",
      "Epoch 567/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0420 - val_loss: 0.2748\n",
      "Epoch 568/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.1391 - val_loss: 0.0024\n",
      "Epoch 569/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.0615 - val_loss: -0.0460\n",
      "Epoch 570/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.0325 - val_loss: -0.0107\n",
      "Epoch 571/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.0807 - val_loss: 0.2084\n",
      "Epoch 572/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.1843 - val_loss: 0.0503\n",
      "Epoch 573/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.1366 - val_loss: 0.0093\n",
      "Epoch 574/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -1.0149 - val_loss: 0.1345\n",
      "Epoch 575/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0628 - val_loss: 0.3096\n",
      "Epoch 576/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0072 - val_loss: 0.0457\n",
      "Epoch 577/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.1925 - val_loss: 0.5006\n",
      "Epoch 578/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.1723 - val_loss: 0.3207\n",
      "Epoch 579/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2095 - val_loss: -0.0038\n",
      "Epoch 580/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.0961 - val_loss: 0.1600\n",
      "Epoch 581/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2809 - val_loss: -0.3407\n",
      "Epoch 582/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.2978 - val_loss: -0.1113\n",
      "Epoch 583/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.2122 - val_loss: 0.1506\n",
      "Epoch 584/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.2973 - val_loss: 0.1085\n",
      "Epoch 585/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3264 - val_loss: -0.1900\n",
      "Epoch 586/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2680 - val_loss: 0.0969\n",
      "Epoch 587/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3200 - val_loss: -0.1917\n",
      "Epoch 588/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2519 - val_loss: 0.1236\n",
      "Epoch 589/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2656 - val_loss: -0.1052\n",
      "Epoch 590/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2798 - val_loss: -0.3217\n",
      "Epoch 591/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2719 - val_loss: -0.0554\n",
      "Epoch 592/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2498 - val_loss: 0.0886\n",
      "Epoch 593/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2370 - val_loss: -0.3138\n",
      "Epoch 594/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.3756 - val_loss: 0.0066\n",
      "Epoch 595/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.3178 - val_loss: 0.1248\n",
      "Epoch 596/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.2942 - val_loss: -0.3378\n",
      "Epoch 597/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3345 - val_loss: -0.3629\n",
      "Epoch 598/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3551 - val_loss: -0.1477\n",
      "Epoch 599/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.2640 - val_loss: -0.2767\n",
      "Epoch 600/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4693 - val_loss: -0.3093\n",
      "Epoch 601/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3663 - val_loss: -0.5410\n",
      "Epoch 602/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4637 - val_loss: -0.2287\n",
      "Epoch 603/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3106 - val_loss: -0.0974\n",
      "Epoch 604/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.3800 - val_loss: 0.0848\n",
      "Epoch 605/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.3785 - val_loss: -0.4120\n",
      "Epoch 606/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.4408 - val_loss: -0.2214\n",
      "Epoch 607/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.4312 - val_loss: -0.0362\n",
      "Epoch 608/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5316 - val_loss: -0.2288\n",
      "Epoch 609/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4679 - val_loss: -0.1542\n",
      "Epoch 610/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4514 - val_loss: -0.4108\n",
      "Epoch 611/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4757 - val_loss: -0.7325\n",
      "Epoch 612/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5820 - val_loss: -0.4261\n",
      "Epoch 613/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5701 - val_loss: -0.4603\n",
      "Epoch 614/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5075 - val_loss: -0.2388\n",
      "Epoch 615/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4822 - val_loss: -0.3904\n",
      "Epoch 616/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5051 - val_loss: -0.3732\n",
      "Epoch 617/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.5601 - val_loss: -0.1757\n",
      "Epoch 618/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6525 - val_loss: -0.8508\n",
      "Epoch 619/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.5930 - val_loss: -0.6521\n",
      "Epoch 620/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6326 - val_loss: -0.6671\n",
      "Epoch 621/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6314 - val_loss: -0.6257\n",
      "Epoch 622/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6206 - val_loss: -0.4459\n",
      "Epoch 623/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.4881 - val_loss: -0.3363\n",
      "Epoch 624/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6062 - val_loss: -0.5934\n",
      "Epoch 625/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6151 - val_loss: -0.3819\n",
      "Epoch 626/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6240 - val_loss: -0.7582\n",
      "Epoch 627/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.7453 - val_loss: -0.7747\n",
      "Epoch 628/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.5902 - val_loss: -0.4516\n",
      "Epoch 629/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6028 - val_loss: -0.5950\n",
      "Epoch 630/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6396 - val_loss: -0.8006\n",
      "Epoch 631/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.7175 - val_loss: -0.8725\n",
      "Epoch 632/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6459 - val_loss: -0.5039\n",
      "Epoch 633/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7314 - val_loss: -0.5289\n",
      "Epoch 634/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6810 - val_loss: -0.4893\n",
      "Epoch 635/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7460 - val_loss: -0.8369\n",
      "Epoch 636/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7152 - val_loss: -0.7475\n",
      "Epoch 637/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7204 - val_loss: -0.5038\n",
      "Epoch 638/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.7633 - val_loss: -0.7365\n",
      "Epoch 639/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.6540 - val_loss: -0.7853\n",
      "Epoch 640/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.6511 - val_loss: -0.6886\n",
      "Epoch 641/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7125 - val_loss: -0.7651\n",
      "Epoch 642/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7300 - val_loss: -0.4138\n",
      "Epoch 643/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7928 - val_loss: -0.4411\n",
      "Epoch 644/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7885 - val_loss: -0.3547\n",
      "Epoch 645/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7107 - val_loss: -0.7338\n",
      "Epoch 646/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7136 - val_loss: -0.6760\n",
      "Epoch 647/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7446 - val_loss: -0.7484\n",
      "Epoch 648/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8418 - val_loss: -0.6328\n",
      "Epoch 649/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.7890 - val_loss: -0.8691\n",
      "Epoch 650/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8622 - val_loss: -1.0003\n",
      "Epoch 651/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8189 - val_loss: 0.8400\n",
      "Epoch 652/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8147 - val_loss: -1.1802\n",
      "Epoch 653/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8787 - val_loss: -0.4729\n",
      "Epoch 654/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8616 - val_loss: -0.5873\n",
      "Epoch 655/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.8772 - val_loss: -0.7643\n",
      "Epoch 656/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8581 - val_loss: -1.0601\n",
      "Epoch 657/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8291 - val_loss: -0.6325\n",
      "Epoch 658/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8647 - val_loss: -0.6188\n",
      "Epoch 659/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8219 - val_loss: -0.9832\n",
      "Epoch 660/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8964 - val_loss: -1.1172\n",
      "Epoch 661/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8760 - val_loss: -1.1367\n",
      "Epoch 662/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.9204 - val_loss: -0.9851\n",
      "Epoch 663/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8953 - val_loss: -1.0988\n",
      "Epoch 664/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -1.9604 - val_loss: -0.9745\n",
      "Epoch 665/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.9460 - val_loss: -1.2032\n",
      "Epoch 666/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.9440 - val_loss: -0.9633\n",
      "Epoch 667/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.8974 - val_loss: -1.1263\n",
      "Epoch 668/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -1.9419 - val_loss: -0.8284\n",
      "Epoch 669/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.9824 - val_loss: -1.0515\n",
      "Epoch 670/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.0173 - val_loss: -1.2860\n",
      "Epoch 671/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.9405 - val_loss: -0.9553\n",
      "Epoch 672/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -1.9408 - val_loss: -1.1497\n",
      "Epoch 673/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.0705 - val_loss: -1.2110\n",
      "Epoch 674/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -1.9916 - val_loss: -0.7020\n",
      "Epoch 675/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.0314 - val_loss: -0.7998\n",
      "Epoch 676/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.0158 - val_loss: -0.9693\n",
      "Epoch 677/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.0077 - val_loss: -1.0961\n",
      "Epoch 678/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.1102 - val_loss: -0.7144\n",
      "Epoch 679/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.0820 - val_loss: -1.0426\n",
      "Epoch 680/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.9637 - val_loss: -1.3394\n",
      "Epoch 681/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.0927 - val_loss: -1.0853\n",
      "Epoch 682/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.0322 - val_loss: -1.2935\n",
      "Epoch 683/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.1621 - val_loss: -1.2586\n",
      "Epoch 684/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.1025 - val_loss: -1.2954\n",
      "Epoch 685/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.1693 - val_loss: -0.7005\n",
      "Epoch 686/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.1679 - val_loss: -1.1667\n",
      "Epoch 687/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.0261 - val_loss: -0.8778\n",
      "Epoch 688/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -1.9591 - val_loss: -1.3221\n",
      "Epoch 689/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1365 - val_loss: -1.2871\n",
      "Epoch 690/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1828 - val_loss: -1.1215\n",
      "Epoch 691/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1329 - val_loss: -1.2007\n",
      "Epoch 692/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1807 - val_loss: -1.1362\n",
      "Epoch 693/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1580 - val_loss: -1.3082\n",
      "Epoch 694/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2487 - val_loss: -1.1938\n",
      "Epoch 695/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2487 - val_loss: -1.0295\n",
      "Epoch 696/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2491 - val_loss: -0.9814\n",
      "Epoch 697/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2442 - val_loss: -1.4011\n",
      "Epoch 698/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2139 - val_loss: -1.0568\n",
      "Epoch 699/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.2190 - val_loss: -0.9192\n",
      "Epoch 700/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.2008 - val_loss: -1.0401\n",
      "Epoch 701/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2909 - val_loss: -1.4458\n",
      "Epoch 702/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2842 - val_loss: -1.1395\n",
      "Epoch 703/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.2554 - val_loss: -1.3549\n",
      "Epoch 704/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2560 - val_loss: -1.1693\n",
      "Epoch 705/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.2394 - val_loss: -1.2498\n",
      "Epoch 706/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.1701 - val_loss: -1.2209\n",
      "Epoch 707/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2348 - val_loss: -1.2896\n",
      "Epoch 708/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4081 - val_loss: -1.0465\n",
      "Epoch 709/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.2338 - val_loss: -1.2378\n",
      "Epoch 710/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.3424 - val_loss: -1.1356\n",
      "Epoch 711/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3485 - val_loss: -1.4591\n",
      "Epoch 712/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3877 - val_loss: -1.6297\n",
      "Epoch 713/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3987 - val_loss: -1.6953\n",
      "Epoch 714/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2778 - val_loss: -1.5785\n",
      "Epoch 715/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.2782 - val_loss: -1.3080\n",
      "Epoch 716/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3825 - val_loss: -1.1558\n",
      "Epoch 717/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3971 - val_loss: -1.2973\n",
      "Epoch 718/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3032 - val_loss: -1.4945\n",
      "Epoch 719/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3175 - val_loss: -1.3736\n",
      "Epoch 720/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4435 - val_loss: -1.3106\n",
      "Epoch 721/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3651 - val_loss: -1.4623\n",
      "Epoch 722/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4588 - val_loss: -1.3178\n",
      "Epoch 723/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4095 - val_loss: -1.4658\n",
      "Epoch 724/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5371 - val_loss: -1.4618\n",
      "Epoch 725/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5476 - val_loss: -1.3598\n",
      "Epoch 726/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4402 - val_loss: -1.3349\n",
      "Epoch 727/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.3596 - val_loss: -1.5463\n",
      "Epoch 728/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4592 - val_loss: -1.2586\n",
      "Epoch 729/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5344 - val_loss: -1.6592\n",
      "Epoch 730/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5617 - val_loss: -1.5430\n",
      "Epoch 731/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4849 - val_loss: -1.6444\n",
      "Epoch 732/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4775 - val_loss: -1.6249\n",
      "Epoch 733/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.5034 - val_loss: -1.3829\n",
      "Epoch 734/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4579 - val_loss: -1.5621\n",
      "Epoch 735/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.4953 - val_loss: -1.5676\n",
      "Epoch 736/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5129 - val_loss: -1.3723\n",
      "Epoch 737/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5059 - val_loss: -1.4739\n",
      "Epoch 738/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5384 - val_loss: -1.4281\n",
      "Epoch 739/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5029 - val_loss: -1.4601\n",
      "Epoch 740/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5007 - val_loss: -1.5062\n",
      "Epoch 741/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5686 - val_loss: -1.6579\n",
      "Epoch 742/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6108 - val_loss: -1.3328\n",
      "Epoch 743/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5491 - val_loss: -1.7557\n",
      "Epoch 744/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5478 - val_loss: -1.6369\n",
      "Epoch 745/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.6576 - val_loss: -1.5106\n",
      "Epoch 746/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.7307 - val_loss: -1.7239\n",
      "Epoch 747/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6051 - val_loss: -1.3074\n",
      "Epoch 748/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5646 - val_loss: -1.4738\n",
      "Epoch 749/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.6072 - val_loss: -1.3817\n",
      "Epoch 750/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6279 - val_loss: -1.9291\n",
      "Epoch 751/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.5706 - val_loss: -1.8139\n",
      "Epoch 752/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6671 - val_loss: -1.7584\n",
      "Epoch 753/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.7226 - val_loss: -1.6449\n",
      "Epoch 754/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6531 - val_loss: -1.5450\n",
      "Epoch 755/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6273 - val_loss: -1.7998\n",
      "Epoch 756/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6036 - val_loss: -1.7559\n",
      "Epoch 757/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.6953 - val_loss: -1.7082\n",
      "Epoch 758/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.7428 - val_loss: -1.3230\n",
      "Epoch 759/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.7057 - val_loss: -1.8632\n",
      "Epoch 760/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6606 - val_loss: -1.7064\n",
      "Epoch 761/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6903 - val_loss: -1.3000\n",
      "Epoch 762/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.6111 - val_loss: -1.6681\n",
      "Epoch 763/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.8016 - val_loss: -1.6116\n",
      "Epoch 764/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6779 - val_loss: -1.5876\n",
      "Epoch 765/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.7003 - val_loss: -1.7668\n",
      "Epoch 766/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.7498 - val_loss: -1.8983\n",
      "Epoch 767/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.6716 - val_loss: -1.8251\n",
      "Epoch 768/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.7100 - val_loss: -1.7234\n",
      "Epoch 769/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.8026 - val_loss: -1.8503\n",
      "Epoch 770/1000\n",
      "127/127 [==============================] - 1s 6ms/step - loss: -2.8762 - val_loss: -2.1423\n",
      "Epoch 771/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.8456 - val_loss: -1.5007\n",
      "Epoch 772/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.6876 - val_loss: -1.8221\n",
      "Epoch 773/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.7905 - val_loss: -1.9821\n",
      "Epoch 774/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.7633 - val_loss: -1.9739\n",
      "Epoch 775/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.8906 - val_loss: -1.8783\n",
      "Epoch 776/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.8302 - val_loss: -1.9100\n",
      "Epoch 777/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.8566 - val_loss: -2.1618\n",
      "Epoch 778/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.8695 - val_loss: -2.0652\n",
      "Epoch 779/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.7680 - val_loss: -1.9424\n",
      "Epoch 780/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.8372 - val_loss: -2.0371\n",
      "Epoch 781/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.8321 - val_loss: -2.0382\n",
      "Epoch 782/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9297 - val_loss: -1.8773\n",
      "Epoch 783/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9366 - val_loss: -2.1365\n",
      "Epoch 784/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9516 - val_loss: -1.9133\n",
      "Epoch 785/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.8884 - val_loss: -1.7356\n",
      "Epoch 786/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9074 - val_loss: -2.0147\n",
      "Epoch 787/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9119 - val_loss: -2.2412\n",
      "Epoch 788/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9260 - val_loss: -2.0547\n",
      "Epoch 789/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.9746 - val_loss: -1.9328\n",
      "Epoch 790/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.9134 - val_loss: -1.9811\n",
      "Epoch 791/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -2.9297 - val_loss: -2.0798\n",
      "Epoch 792/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.9534 - val_loss: -1.9618\n",
      "Epoch 793/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.9714 - val_loss: -1.5694\n",
      "Epoch 794/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -2.9934 - val_loss: -1.8340\n",
      "Epoch 795/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9435 - val_loss: -1.9608\n",
      "Epoch 796/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9945 - val_loss: -2.0913\n",
      "Epoch 797/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.8595 - val_loss: -1.9184\n",
      "Epoch 798/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.9322 - val_loss: -1.6998\n",
      "Epoch 799/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9567 - val_loss: -2.1403\n",
      "Epoch 800/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0614 - val_loss: -2.0599\n",
      "Epoch 801/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0356 - val_loss: -2.2833\n",
      "Epoch 802/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0798 - val_loss: -2.2043\n",
      "Epoch 803/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -3.1443 - val_loss: -1.9345\n",
      "Epoch 804/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -3.0907 - val_loss: -1.9218\n",
      "Epoch 805/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -2.9933 - val_loss: -2.0328\n",
      "Epoch 806/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0091 - val_loss: -1.9653\n",
      "Epoch 807/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -2.9777 - val_loss: -1.7167\n",
      "Epoch 808/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1314 - val_loss: -1.9342\n",
      "Epoch 809/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -3.0490 - val_loss: -2.0316\n",
      "Epoch 810/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -3.0599 - val_loss: -2.1647\n",
      "Epoch 811/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -3.0494 - val_loss: -2.0979\n",
      "Epoch 812/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1660 - val_loss: -2.4104\n",
      "Epoch 813/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1569 - val_loss: -2.0055\n",
      "Epoch 814/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0939 - val_loss: -2.0823\n",
      "Epoch 815/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0511 - val_loss: -2.0384\n",
      "Epoch 816/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1130 - val_loss: -2.3645\n",
      "Epoch 817/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1593 - val_loss: -1.9183\n",
      "Epoch 818/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2388 - val_loss: -2.3231\n",
      "Epoch 819/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2660 - val_loss: -2.3782\n",
      "Epoch 820/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2226 - val_loss: -2.1935\n",
      "Epoch 821/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2469 - val_loss: -2.3192\n",
      "Epoch 822/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.0405 - val_loss: -2.1802\n",
      "Epoch 823/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2265 - val_loss: -2.0692\n",
      "Epoch 824/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1271 - val_loss: -1.8214\n",
      "Epoch 825/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1991 - val_loss: -2.2876\n",
      "Epoch 826/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1456 - val_loss: -2.0458\n",
      "Epoch 827/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1546 - val_loss: -2.0721\n",
      "Epoch 828/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2069 - val_loss: -2.3600\n",
      "Epoch 829/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2506 - val_loss: -2.3331\n",
      "Epoch 830/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2235 - val_loss: -2.3939\n",
      "Epoch 831/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3007 - val_loss: -1.9865\n",
      "Epoch 832/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2655 - val_loss: -2.3402\n",
      "Epoch 833/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2130 - val_loss: -2.0453\n",
      "Epoch 834/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.1109 - val_loss: -2.3693\n",
      "Epoch 835/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3763 - val_loss: -2.4570\n",
      "Epoch 836/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2901 - val_loss: -2.3240\n",
      "Epoch 837/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3212 - val_loss: -2.5105\n",
      "Epoch 838/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2185 - val_loss: -2.4540\n",
      "Epoch 839/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.2624 - val_loss: -2.2853\n",
      "Epoch 840/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3222 - val_loss: -2.2405\n",
      "Epoch 841/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3500 - val_loss: -2.3983\n",
      "Epoch 842/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3169 - val_loss: -2.6138\n",
      "Epoch 843/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3392 - val_loss: -2.4730\n",
      "Epoch 844/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3176 - val_loss: -2.5674\n",
      "Epoch 845/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3325 - val_loss: -2.6473\n",
      "Epoch 846/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3434 - val_loss: -2.4539\n",
      "Epoch 847/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4088 - val_loss: -2.5652\n",
      "Epoch 848/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4456 - val_loss: -2.6429\n",
      "Epoch 849/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4582 - val_loss: -2.4869\n",
      "Epoch 850/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4940 - val_loss: -2.5666\n",
      "Epoch 851/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4513 - val_loss: -2.7374\n",
      "Epoch 852/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4637 - val_loss: -2.6699\n",
      "Epoch 853/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4236 - val_loss: -2.5945\n",
      "Epoch 854/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4888 - val_loss: -2.6223\n",
      "Epoch 855/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4773 - val_loss: -2.6351\n",
      "Epoch 856/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5006 - val_loss: -2.5130\n",
      "Epoch 857/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4991 - val_loss: -2.5041\n",
      "Epoch 858/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4915 - val_loss: -2.5172\n",
      "Epoch 859/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -3.4891 - val_loss: -2.4671\n",
      "Epoch 860/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -3.4563 - val_loss: -2.5340\n",
      "Epoch 861/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -3.5294 - val_loss: -2.8129\n",
      "Epoch 862/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5699 - val_loss: -2.3280\n",
      "Epoch 863/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5608 - val_loss: -2.5265\n",
      "Epoch 864/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4762 - val_loss: -2.7503\n",
      "Epoch 865/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6010 - val_loss: -2.7480\n",
      "Epoch 866/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5204 - val_loss: -2.3157\n",
      "Epoch 867/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5364 - val_loss: -2.7935\n",
      "Epoch 868/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5526 - val_loss: -2.7762\n",
      "Epoch 869/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5773 - val_loss: -2.4384\n",
      "Epoch 870/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.3994 - val_loss: -2.4941\n",
      "Epoch 871/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5650 - val_loss: -2.7265\n",
      "Epoch 872/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6003 - val_loss: -2.7737\n",
      "Epoch 873/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5597 - val_loss: -2.4319\n",
      "Epoch 874/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6660 - val_loss: -2.7473\n",
      "Epoch 875/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6734 - val_loss: -2.9226\n",
      "Epoch 876/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6837 - val_loss: -2.8170\n",
      "Epoch 877/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5533 - val_loss: -2.4804\n",
      "Epoch 878/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6950 - val_loss: -2.6183\n",
      "Epoch 879/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5462 - val_loss: -2.7178\n",
      "Epoch 880/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6059 - val_loss: -2.8438\n",
      "Epoch 881/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5442 - val_loss: -2.5231\n",
      "Epoch 882/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.4444 - val_loss: -2.6832\n",
      "Epoch 883/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6498 - val_loss: -2.8776\n",
      "Epoch 884/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7098 - val_loss: -2.8707\n",
      "Epoch 885/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7700 - val_loss: -2.5352\n",
      "Epoch 886/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.5923 - val_loss: -2.3560\n",
      "Epoch 887/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6160 - val_loss: -2.6656\n",
      "Epoch 888/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7069 - val_loss: -2.6517\n",
      "Epoch 889/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6790 - val_loss: -2.5686\n",
      "Epoch 890/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7003 - val_loss: -2.7049\n",
      "Epoch 891/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7762 - val_loss: -2.8711\n",
      "Epoch 892/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7086 - val_loss: -2.9508\n",
      "Epoch 893/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6970 - val_loss: -3.0673\n",
      "Epoch 894/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7702 - val_loss: -2.8147\n",
      "Epoch 895/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7419 - val_loss: -2.6270\n",
      "Epoch 896/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6582 - val_loss: -2.9367\n",
      "Epoch 897/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7841 - val_loss: -2.7260\n",
      "Epoch 898/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6527 - val_loss: -2.9091\n",
      "Epoch 899/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7601 - val_loss: -2.7123\n",
      "Epoch 900/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7357 - val_loss: -2.6930\n",
      "Epoch 901/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7847 - val_loss: -2.9378\n",
      "Epoch 902/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7700 - val_loss: -3.0721\n",
      "Epoch 903/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.6860 - val_loss: -2.7248\n",
      "Epoch 904/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8229 - val_loss: -2.6590\n",
      "Epoch 905/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7397 - val_loss: -2.7004\n",
      "Epoch 906/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7649 - val_loss: -2.5536\n",
      "Epoch 907/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7410 - val_loss: -2.9918\n",
      "Epoch 908/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8449 - val_loss: -2.9325\n",
      "Epoch 909/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8508 - val_loss: -3.0902\n",
      "Epoch 910/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8217 - val_loss: -2.9832\n",
      "Epoch 911/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9237 - val_loss: -3.1560\n",
      "Epoch 912/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9220 - val_loss: -2.8743\n",
      "Epoch 913/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9188 - val_loss: -2.9304\n",
      "Epoch 914/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8939 - val_loss: -2.9058\n",
      "Epoch 915/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8100 - val_loss: -3.0159\n",
      "Epoch 916/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.7739 - val_loss: -2.9220\n",
      "Epoch 917/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9116 - val_loss: -2.5726\n",
      "Epoch 918/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9035 - val_loss: -2.8136\n",
      "Epoch 919/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9035 - val_loss: -2.9162\n",
      "Epoch 920/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.8924 - val_loss: -3.0509\n",
      "Epoch 921/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9452 - val_loss: -3.1782\n",
      "Epoch 922/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9546 - val_loss: -3.2445\n",
      "Epoch 923/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9258 - val_loss: -2.9149\n",
      "Epoch 924/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9720 - val_loss: -3.0307\n",
      "Epoch 925/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9338 - val_loss: -2.9219\n",
      "Epoch 926/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0007 - val_loss: -3.1167\n",
      "Epoch 927/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0682 - val_loss: -3.0003\n",
      "Epoch 928/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9896 - val_loss: -3.0669\n",
      "Epoch 929/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0358 - val_loss: -3.1030\n",
      "Epoch 930/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0523 - val_loss: -3.2410\n",
      "Epoch 931/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9127 - val_loss: -2.9611\n",
      "Epoch 932/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0232 - val_loss: -3.2611\n",
      "Epoch 933/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1208 - val_loss: -3.0489\n",
      "Epoch 934/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9134 - val_loss: -3.2945\n",
      "Epoch 935/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9959 - val_loss: -2.6876\n",
      "Epoch 936/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0367 - val_loss: -3.1845\n",
      "Epoch 937/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0560 - val_loss: -2.8284\n",
      "Epoch 938/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9735 - val_loss: -3.0600\n",
      "Epoch 939/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9651 - val_loss: -3.1131\n",
      "Epoch 940/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9820 - val_loss: -2.9373\n",
      "Epoch 941/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9851 - val_loss: -3.1220\n",
      "Epoch 942/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0373 - val_loss: -3.1368\n",
      "Epoch 943/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1565 - val_loss: -3.1678\n",
      "Epoch 944/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1909 - val_loss: -3.0273\n",
      "Epoch 945/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -3.9695 - val_loss: -3.1087\n",
      "Epoch 946/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0586 - val_loss: -3.0160\n",
      "Epoch 947/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.0615 - val_loss: -3.0472\n",
      "Epoch 948/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1066 - val_loss: -3.2579\n",
      "Epoch 949/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.2011 - val_loss: -3.2862\n",
      "Epoch 950/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1210 - val_loss: -3.0418\n",
      "Epoch 951/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1017 - val_loss: -3.2189\n",
      "Epoch 952/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.2111 - val_loss: -3.2221\n",
      "Epoch 953/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.1199 - val_loss: -3.2021\n",
      "Epoch 954/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1430 - val_loss: -3.1094\n",
      "Epoch 955/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1806 - val_loss: -3.2282\n",
      "Epoch 956/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1191 - val_loss: -3.1071\n",
      "Epoch 957/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.1852 - val_loss: -3.2984\n",
      "Epoch 958/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.1883 - val_loss: -3.4484\n",
      "Epoch 959/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -4.2214 - val_loss: -3.1853\n",
      "Epoch 960/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.2215 - val_loss: -2.7637\n",
      "Epoch 961/1000\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -4.0797 - val_loss: -3.0811\n",
      "Epoch 962/1000\n",
      "127/127 [==============================] - 1s 6ms/step - loss: -4.1342 - val_loss: -3.4180\n",
      "Epoch 963/1000\n",
      "127/127 [==============================] - 1s 6ms/step - loss: -4.1848 - val_loss: -3.3144\n",
      "Epoch 964/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.1202 - val_loss: -3.3250\n",
      "Epoch 965/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.3243 - val_loss: -3.4474\n",
      "Epoch 966/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.2791 - val_loss: -3.3486\n",
      "Epoch 967/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.3000 - val_loss: -3.2673\n",
      "Epoch 968/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.2949 - val_loss: -3.0871\n",
      "Epoch 969/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.3111 - val_loss: -3.1476\n",
      "Epoch 970/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.3370 - val_loss: -3.5377\n",
      "Epoch 971/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.2752 - val_loss: -3.3724\n",
      "Epoch 972/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3551 - val_loss: -3.3045\n",
      "Epoch 973/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.2919 - val_loss: -3.3748\n",
      "Epoch 974/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3793 - val_loss: -3.1436\n",
      "Epoch 975/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3052 - val_loss: -3.1645\n",
      "Epoch 976/1000\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -4.3738 - val_loss: -3.4855\n",
      "Epoch 977/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.2779 - val_loss: -3.3490\n",
      "Epoch 978/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.2626 - val_loss: -3.1273\n",
      "Epoch 979/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.2586 - val_loss: -3.5442\n",
      "Epoch 980/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3929 - val_loss: -3.1552\n",
      "Epoch 981/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3231 - val_loss: -3.4813\n",
      "Epoch 982/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.2599 - val_loss: -3.3043\n",
      "Epoch 983/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.1914 - val_loss: -3.4042\n",
      "Epoch 984/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3132 - val_loss: -3.3808\n",
      "Epoch 985/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.2637 - val_loss: -3.3864\n",
      "Epoch 986/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3761 - val_loss: -3.5903\n",
      "Epoch 987/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.4142 - val_loss: -3.6254\n",
      "Epoch 988/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.3752 - val_loss: -3.5527\n",
      "Epoch 989/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4797 - val_loss: -3.5078\n",
      "Epoch 990/1000\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -4.4950 - val_loss: -3.7332\n",
      "Epoch 991/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3701 - val_loss: -3.3792\n",
      "Epoch 992/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4210 - val_loss: -3.6751\n",
      "Epoch 993/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4800 - val_loss: -3.7611\n",
      "Epoch 994/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4240 - val_loss: -3.4766\n",
      "Epoch 995/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4772 - val_loss: -3.4069\n",
      "Epoch 996/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4621 - val_loss: -3.2847\n",
      "Epoch 997/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4100 - val_loss: -3.1305\n",
      "Epoch 998/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.3893 - val_loss: -3.5979\n",
      "Epoch 999/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4315 - val_loss: -3.4690\n",
      "Epoch 1000/1000\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -4.4617 - val_loss: -3.3347\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(x=X_train, y=y_train, batch_size=128, epochs=1000, validation_split=0.1, callbacks=[tf.keras.callbacks.TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained a loss of -1.5942. The 1D example from medium had a loss of around -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot the loss over the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "#plt.ylim([-5, 5])\n",
    "plt.plot(fit.history['loss'])\n",
    "plt.plot(fit.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions from our model by sampling the posterior distribution. Each mixture model produces a mean and sigma in each dimension for each test observation rather than a point estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 8 µs, total: 14 µs\n",
      "Wall time: 526 µs\n"
     ]
    }
   ],
   "source": [
    "# Returns the predictions of the parameters of the distributions and weights\n",
    "%time\n",
    "preds = model.predict(X_test)\n",
    "samples_list = []\n",
    "# Obtain 10 samples per prediction\n",
    "for i in range(10):\n",
    "    samples_list.append(np.apply_along_axis(mdn.sample_from_output, 1, preds, l, k, temp=1.0, sigma_temp=1.0))\n",
    "\n",
    "# Average the samples for our predicitons\n",
    "y_samples = np.mean(np.array(samples_list),axis=0)\n",
    "y_samples = y_samples.reshape(2000,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcuate the entropy between each predicted distribution and test distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.084935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.273626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.014521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.048432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.722300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  2000.000000\n",
       "mean      0.084935\n",
       "std       0.273626\n",
       "min       0.000133\n",
       "25%       0.005137\n",
       "50%       0.014521\n",
       "75%       0.048432\n",
       "max       4.722300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "ent = []\n",
    "# Turn all negative preds to 0\n",
    "y_samples = np.clip(y_samples,0, a_max=None)\n",
    "for i in range(len(y_test)):\n",
    "     e = entropy(y_samples[i], y_test[i])\n",
    "     ent.append(e if e != np.inf else 1000)   \n",
    "display(pd.DataFrame(ent).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.499647</td>\n",
       "      <td>2.496840</td>\n",
       "      <td>2.503687</td>\n",
       "      <td>2.503855</td>\n",
       "      <td>2.504160</td>\n",
       "      <td>2.492263</td>\n",
       "      <td>2.488502</td>\n",
       "      <td>2.493412</td>\n",
       "      <td>2.501250</td>\n",
       "      <td>2.499714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.189138</td>\n",
       "      <td>0.191169</td>\n",
       "      <td>0.192166</td>\n",
       "      <td>0.194781</td>\n",
       "      <td>0.187986</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>0.196444</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>0.192521</td>\n",
       "      <td>0.192397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.910273</td>\n",
       "      <td>1.922096</td>\n",
       "      <td>1.915850</td>\n",
       "      <td>1.910727</td>\n",
       "      <td>1.955644</td>\n",
       "      <td>1.922488</td>\n",
       "      <td>1.919669</td>\n",
       "      <td>1.922958</td>\n",
       "      <td>1.916764</td>\n",
       "      <td>1.923399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.400764</td>\n",
       "      <td>2.402421</td>\n",
       "      <td>2.408334</td>\n",
       "      <td>2.400783</td>\n",
       "      <td>2.402356</td>\n",
       "      <td>2.395525</td>\n",
       "      <td>2.390674</td>\n",
       "      <td>2.394832</td>\n",
       "      <td>2.402554</td>\n",
       "      <td>2.406376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.497742</td>\n",
       "      <td>2.496651</td>\n",
       "      <td>2.500411</td>\n",
       "      <td>2.501384</td>\n",
       "      <td>2.498127</td>\n",
       "      <td>2.498449</td>\n",
       "      <td>2.493083</td>\n",
       "      <td>2.495152</td>\n",
       "      <td>2.500687</td>\n",
       "      <td>2.499824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.594481</td>\n",
       "      <td>2.598622</td>\n",
       "      <td>2.598980</td>\n",
       "      <td>2.605112</td>\n",
       "      <td>2.596828</td>\n",
       "      <td>2.592149</td>\n",
       "      <td>2.581927</td>\n",
       "      <td>2.593751</td>\n",
       "      <td>2.589715</td>\n",
       "      <td>2.590080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.096285</td>\n",
       "      <td>3.061361</td>\n",
       "      <td>3.078503</td>\n",
       "      <td>3.079951</td>\n",
       "      <td>3.077315</td>\n",
       "      <td>3.076648</td>\n",
       "      <td>3.097432</td>\n",
       "      <td>3.077092</td>\n",
       "      <td>3.070284</td>\n",
       "      <td>3.093505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      2.499647     2.496840     2.503687     2.503855     2.504160   \n",
       "std       0.189138     0.191169     0.192166     0.194781     0.187986   \n",
       "min       1.910273     1.922096     1.915850     1.910727     1.955644   \n",
       "25%       2.400764     2.402421     2.408334     2.400783     2.402356   \n",
       "50%       2.497742     2.496651     2.500411     2.501384     2.498127   \n",
       "75%       2.594481     2.598622     2.598980     2.605112     2.596828   \n",
       "max       3.096285     3.061361     3.078503     3.079951     3.077315   \n",
       "\n",
       "                 5            6            7            8            9  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  \n",
       "mean      2.492263     2.488502     2.493412     2.501250     2.499714  \n",
       "std       0.189792     0.196444     0.200862     0.192521     0.192397  \n",
       "min       1.922488     1.919669     1.922958     1.916764     1.923399  \n",
       "25%       2.395525     2.390674     2.394832     2.402554     2.406376  \n",
       "50%       2.498449     2.493083     2.495152     2.500687     2.499824  \n",
       "75%       2.592149     2.581927     2.593751     2.589715     2.590080  \n",
       "max       3.076648     3.097432     3.077092     3.070284     3.093505  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.7499 - val_loss: -12.9041\n",
      "Epoch 2/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.7504 - val_loss: -12.6577\n",
      "Epoch 3/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.6996 - val_loss: -12.7451\n",
      "Epoch 4/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.8146 - val_loss: -12.6038\n",
      "Epoch 5/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.7556 - val_loss: -12.5374\n",
      "Epoch 6/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.7633 - val_loss: -12.8764\n",
      "Epoch 7/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8177 - val_loss: -12.7748\n",
      "Epoch 8/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8086 - val_loss: -12.7213\n",
      "Epoch 9/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.7989 - val_loss: -12.9274\n",
      "Epoch 10/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8235 - val_loss: -12.8142\n",
      "Epoch 11/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8151 - val_loss: -12.7607\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8081 - val_loss: -12.8716\n",
      "Epoch 13/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.8687 - val_loss: -12.7261\n",
      "Epoch 14/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.7690 - val_loss: -12.5678\n",
      "Epoch 15/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.7881 - val_loss: -12.8158\n",
      "Epoch 16/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.8162 - val_loss: -12.7908\n",
      "Epoch 17/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9035 - val_loss: -12.7388\n",
      "Epoch 18/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8622 - val_loss: -12.7029\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8045 - val_loss: -12.7248\n",
      "Epoch 20/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8394 - val_loss: -12.7523\n",
      "Epoch 21/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8745 - val_loss: -12.9073\n",
      "Epoch 22/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -12.7855 - val_loss: -12.7961\n",
      "Epoch 23/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8779 - val_loss: -12.7417\n",
      "Epoch 24/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.8121 - val_loss: -12.8214\n",
      "Epoch 25/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.8606 - val_loss: -12.9376\n",
      "Epoch 26/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9615 - val_loss: -12.8074\n",
      "Epoch 27/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9832 - val_loss: -12.7839\n",
      "Epoch 28/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9130 - val_loss: -12.8162\n",
      "Epoch 29/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8909 - val_loss: -12.6228\n",
      "Epoch 30/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.8565 - val_loss: -12.9059\n",
      "Epoch 31/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9346 - val_loss: -12.9255\n",
      "Epoch 32/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9349 - val_loss: -12.8429\n",
      "Epoch 33/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9075 - val_loss: -12.9157\n",
      "Epoch 34/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9842 - val_loss: -12.8817\n",
      "Epoch 35/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0081 - val_loss: -12.9441\n",
      "Epoch 36/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9450 - val_loss: -12.7653\n",
      "Epoch 37/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9063 - val_loss: -12.5898\n",
      "Epoch 38/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9082 - val_loss: -12.8559\n",
      "Epoch 39/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9285 - val_loss: -13.1428\n",
      "Epoch 40/100\n",
      "127/127 [==============================] - 0s 3ms/step - loss: -12.9099 - val_loss: -13.0334\n",
      "Epoch 41/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9673 - val_loss: -13.0663\n",
      "Epoch 42/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9771 - val_loss: -12.6779\n",
      "Epoch 43/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9900 - val_loss: -12.9888\n",
      "Epoch 44/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9486 - val_loss: -12.9877\n",
      "Epoch 45/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0108 - val_loss: -12.9601\n",
      "Epoch 46/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0263 - val_loss: -12.9786\n",
      "Epoch 47/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0145 - val_loss: -12.8735\n",
      "Epoch 48/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -12.9969 - val_loss: -13.0549\n",
      "Epoch 49/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0195 - val_loss: -13.1681\n",
      "Epoch 50/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0166 - val_loss: -12.9754\n",
      "Epoch 51/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -12.9813 - val_loss: -13.0339\n",
      "Epoch 52/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0016 - val_loss: -13.0287\n",
      "Epoch 53/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -12.9538 - val_loss: -12.8318\n",
      "Epoch 54/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9744 - val_loss: -12.9357\n",
      "Epoch 55/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0124 - val_loss: -12.9363\n",
      "Epoch 56/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -12.9877 - val_loss: -13.1432\n",
      "Epoch 57/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0396 - val_loss: -12.8241\n",
      "Epoch 58/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0522 - val_loss: -13.0658\n",
      "Epoch 59/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0651 - val_loss: -12.7027\n",
      "Epoch 60/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0190 - val_loss: -12.8995\n",
      "Epoch 61/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0685 - val_loss: -13.0762\n",
      "Epoch 62/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0260 - val_loss: -13.1202\n",
      "Epoch 63/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0648 - val_loss: -12.6347\n",
      "Epoch 64/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0613 - val_loss: -13.0920\n",
      "Epoch 65/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0662 - val_loss: -13.1736\n",
      "Epoch 66/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0754 - val_loss: -12.8637\n",
      "Epoch 67/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -12.9675 - val_loss: -13.0076\n",
      "Epoch 68/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0837 - val_loss: -12.9870\n",
      "Epoch 69/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0830 - val_loss: -12.9708\n",
      "Epoch 70/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0983 - val_loss: -12.8740\n",
      "Epoch 71/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1248 - val_loss: -12.7099\n",
      "Epoch 72/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0593 - val_loss: -13.0546\n",
      "Epoch 73/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1053 - val_loss: -12.7710\n",
      "Epoch 74/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0392 - val_loss: -13.0354\n",
      "Epoch 75/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0925 - val_loss: -12.9469\n",
      "Epoch 76/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0940 - val_loss: -13.0683\n",
      "Epoch 77/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0083 - val_loss: -12.8962\n",
      "Epoch 78/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0748 - val_loss: -13.1359\n",
      "Epoch 79/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.0686 - val_loss: -13.1369\n",
      "Epoch 80/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1390 - val_loss: -13.1247\n",
      "Epoch 81/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1226 - val_loss: -13.1284\n",
      "Epoch 82/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1077 - val_loss: -12.9260\n",
      "Epoch 83/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1030 - val_loss: -12.9545\n",
      "Epoch 84/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.0205 - val_loss: -12.9739\n",
      "Epoch 85/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1210 - val_loss: -13.1764\n",
      "Epoch 86/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1788 - val_loss: -13.2340\n",
      "Epoch 87/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1302 - val_loss: -13.0363\n",
      "Epoch 88/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1641 - val_loss: -13.1120\n",
      "Epoch 89/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1688 - val_loss: -13.0824\n",
      "Epoch 90/100\n",
      "127/127 [==============================] - 0s 4ms/step - loss: -13.0806 - val_loss: -12.9660\n",
      "Epoch 91/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1211 - val_loss: -13.1374\n",
      "Epoch 92/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1672 - val_loss: -12.9726\n",
      "Epoch 93/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1739 - val_loss: -13.0782\n",
      "Epoch 94/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1181 - val_loss: -13.2097\n",
      "Epoch 95/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1267 - val_loss: -13.1400\n",
      "Epoch 96/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1732 - val_loss: -13.0458\n",
      "Epoch 97/100\n",
      "127/127 [==============================] - 1s 4ms/step - loss: -13.1385 - val_loss: -13.1376\n",
      "Epoch 98/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1648 - val_loss: -13.0790\n",
      "Epoch 99/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1207 - val_loss: -13.0642\n",
      "Epoch 100/100\n",
      "127/127 [==============================] - 1s 5ms/step - loss: -13.1296 - val_loss: -12.8198\n"
     ]
    }
   ],
   "source": [
    "def gen_data_sin(n=1000, cols=2):\n",
    "    # sample uniformly over the interval (0,1)\n",
    "    X = np.random.uniform(0., 1., (n,cols)).astype(np.float32)    \n",
    "    # Add 2 to have strictly positive Y\n",
    "    y = 2 + (X + 0.3 * np.sin(2 * np.pi * X) + np.random.uniform(-0.1, 0.1, size=(n,cols)).astype(np.float32))\n",
    "    return X,y\n",
    "\n",
    "X_sin,y_sin = gen_data_sin(n=20000, cols=10)\n",
    "\n",
    "X_train_sin, X_test_sin, y_train_sin, y_test_sin = train_test_split(X_sin,y_sin, test_size=0.10, random_state=42)\n",
    "\n",
    "display(pd.DataFrame(y_test_sin).describe())\n",
    "\n",
    "fit = model.fit(x=X_train_sin, y=y_train_sin, batch_size=128, epochs=100, validation_split=0.1, callbacks=[tf.keras.callbacks.TerminateOnNaN()])\n",
    "\n",
    "# Returns the predictions of the parameters of the distributions and weights\n",
    "preds_sin = model.predict(X_test_sin)\n",
    "samples_list_sin = []\n",
    "# Obtain 10 samples per preidciton\n",
    "for i in range(10):\n",
    "    samples_list_sin.append(np.apply_along_axis(mdn.sample_from_output, 1, preds_sin, l, k, temp=1.0, sigma_temp=1.0))\n",
    "\n",
    "# Average the samples for our predicitons\n",
    "y_samples_sin = np.mean(np.array(samples_list),axis=0)\n",
    "y_samples_sin = y_samples_sin.reshape(2000,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.291106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.006736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.013835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.068446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.079490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  2000.000000\n",
       "mean      0.117683\n",
       "std       0.291106\n",
       "min       0.000796\n",
       "25%       0.006736\n",
       "50%       0.013835\n",
       "75%       0.068446\n",
       "max       2.079490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "ent_sin = []\n",
    "# Turn all negative preds to 0\n",
    "y_samples_sin = np.clip(y_samples_sin,0, a_max=None)\n",
    "for i in range(len(y_test)):\n",
    "     e = entropy(y_samples_sin[i], y_test_sin[i])\n",
    "     ent_sin.append(e if e != np.inf else 1000)   \n",
    "display(pd.DataFrame(ent_sin).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 13, 25, 38, 49, 62, 66, 119, 121, 127, 140, 171, 179, 180, 199, 227, 253, 268, 291, 321, 326, 349, 350, 376, 381, 386, 409, 426, 433, 440, 448, 454, 461, 472, 504, 512, 528, 580, 629, 636, 645, 652, 681, 712, 719, 729, 798, 813, 842, 850, 873, 878, 902, 915, 916, 939, 948, 951, 957, 964, 969, 981, 1011, 1017, 1025, 1037, 1048, 1052, 1055, 1080, 1086, 1112, 1169, 1193, 1199, 1249, 1257, 1277, 1280, 1281, 1287, 1291, 1301, 1302, 1331, 1356, 1374, 1386, 1391, 1394, 1398, 1424, 1425, 1442, 1455, 1456, 1474, 1495, 1527, 1536, 1547, 1549, 1555, 1593, 1598, 1603, 1621, 1631, 1644, 1651, 1659, 1689, 1693, 1694, 1707, 1717, 1734, 1737, 1745, 1759, 1773, 1780, 1797, 1802, 1855, 1886, 1891, 1921, 1929, 1956, 1995]\n",
      "[ 3.26747821  6.14933476  2.6585072   3.09475314  2.45635291 -7.58402554\n",
      "  2.65225544  3.26880631  8.37458965  2.3776149 ]\n",
      "[2.3558784 2.478197  2.1245105 2.6911554 2.4723806 2.5258257 2.4309087\n",
      " 2.4078817 2.550756  2.380342 ]\n"
     ]
    }
   ],
   "source": [
    "print([idx for idx,e in enumerate(ent_sin) if e == 1000])\n",
    "print(y_samples_sin[25])\n",
    "print(y_test_sin[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
