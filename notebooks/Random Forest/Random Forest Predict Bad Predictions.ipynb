{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bin_count = 171\n",
    "def create_test_train(data_set_path, test_size=0.10):\n",
    "    \"\"\" Splits a given csv file into testing and training. Target column is all the bins.\"\"\"\n",
    "    # Make sure the columns are set\n",
    "    data_set = pd.read_csv(data_set_path)\n",
    "\n",
    "    # Shuffle the data\n",
    "    data_set = data_set.sample(frac=1, random_state=0)\n",
    " \n",
    "    # Select all except output bins\n",
    "    data_set_X = data_set.drop([f'Output_Bin_{i}' for i in range(bin_count)], axis=1)\n",
    "    # Select only the output bins\n",
    "    data_set_Y = data_set[[f'Output_Bin_{i}' for i in range(bin_count)]]\n",
    "\n",
    "    #Split into training and test data\n",
    "    return train_test_split(data_set_X,\n",
    "                            data_set_Y,\n",
    "                            test_size=test_size, \n",
    "                            random_state=300)\n",
    "\n",
    "filename= \"/project/SDS-capstones-kropko21/uva-astronomy/dust_training_data_all_bins_v2.csv\"\n",
    "X_train, X_test, y_train, y_test = create_test_train(filename, test_size=0.10)\n",
    "\n",
    "def evaluate_fit(y_samples, y_test):\n",
    "    ent = []\n",
    "    js_list = []\n",
    "\n",
    "    # Turn all negative preds to 0\n",
    "    y_samples = np.clip(y_samples,0, a_max=None)\n",
    "    \n",
    "    y_samples_obs = y_samples\n",
    "    y_test_obs = y_test\n",
    "    \n",
    "    # Small constant to prevent inf for 0s\n",
    "    c = 1e-100\n",
    "    \n",
    "    y_test_obs += c\n",
    "    y_samples_obs += c\n",
    "\n",
    "    fits = []\n",
    "    for i in range(len(y_test_obs)):\n",
    "        # Calcuate the two entropy measures\n",
    "        e = entropy(y_test_obs.iloc[i], y_samples_obs[i])\n",
    "        js = jensenshannon(y_test_obs.iloc[i], y_samples_obs[i])\n",
    "        ent.append(e if e != np.inf else 1000)\n",
    "        js_list.append(js)\n",
    "        # Add the index and the two entropy measures to an array to be used for plotting later\n",
    "        fits.append((i, ent, js))\n",
    "    #print(\"Entropy\")\n",
    "    #display(pd.DataFrame(ent).describe())\n",
    "    print(\"Jensen-Shannon\")\n",
    "    display(pd.DataFrame(js_list).describe().apply(lambda s: s.apply('{0:.4f}'.format)))\n",
    "    return fits, js_list\n",
    "\n",
    "def fit_for_model(filename, X_test, y_test):\n",
    "    \"\"\" Loads and fits model from file. Evaluates against X,y test\"\"\"\n",
    "    \n",
    "    rf = load(filename)\n",
    "    preds = rf.predict(X_test)\n",
    "    \n",
    "    # Renormalize samples\n",
    "    preds_normalized = []\n",
    "    for s in preds:\n",
    "        preds_normalized.append(np.divide(s,np.sum(s)))\n",
    "        \n",
    "    preds_df = pd.DataFrame(preds_normalized, columns=[f'Output_Bin_{i}' for i in range(bin_count)])\n",
    "    preds_df.to_csv(\"preds_small_model.csv\")\n",
    "    \n",
    "    return evaluate_fit(preds_normalized, y_test), preds_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jensen-Shannon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142330.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.8159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  142330.0000\n",
       "mean        0.0803\n",
       "std         0.1214\n",
       "min         0.0000\n",
       "25%         0.0052\n",
       "50%         0.0195\n",
       "75%         0.1081\n",
       "max         0.8159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "model_name = '/project/SDS-capstones-kropko21/uva-astronomy-models/rf-model-large.joblib'\n",
    "m1_fit, model_1_preds = fit_for_model(model_name, X_test, y_test)\n",
    "fits, model_1_js_list = m1_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mode Bin Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(np.argmax(y_test.to_numpy(), axis=1) - np.argmax(model_1_preds, axis=1))\n",
    "err_fits_arr = []\n",
    "bin_error = np.abs(np.argmax(y_test.to_numpy(), axis=1) - np.argmax(model_1_preds, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b6dc76d75ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;34m\"Yvalue\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel_1_js_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     })\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mevalDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloess2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xvalue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yvalue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b6dc76d75ba6>\u001b[0m in \u001b[0;36mloess2\u001b[0;34m(xvals, yvals, data, alpha, poly_degree)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_dists\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mW\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mb\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0myvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mlocal_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         iterDF2   = pd.DataFrame({\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2019.10-py3.7/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/software/standard/compiler/gcc/9.2.0/jupyter_conda/2019.10-py3.7/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "def loess2(xvals, yvals, data, alpha, poly_degree=1):\n",
    "    all_data = sorted(zip(data[xvals].tolist(), data[yvals].tolist()), key=lambda x: x[0])\n",
    "    xvals, yvals = zip(*all_data)\n",
    "    evalDF = pd.DataFrame(columns=['v','g'])\n",
    "    n = len(xvals)\n",
    "    m = n + 1\n",
    "    q = int(np.floor(n * alpha) if alpha <= 1.0 else n)\n",
    "    avg_interval = ((max(xvals)-min(xvals))/len(xvals))\n",
    "    v_lb = min(xvals)-(.5*avg_interval)\n",
    "    v_ub = (max(xvals)+(.5*avg_interval))\n",
    "    v = enumerate(np.linspace(start=v_lb, stop=v_ub, num=m), start=1)\n",
    "    xcols = [np.ones_like(xvals)]\n",
    "    for j in range(1, (poly_degree + 1)):\n",
    "        xcols.append([i ** j for i in xvals])\n",
    "    X = np.vstack(xcols).T\n",
    "    for i in v:\n",
    "        iterpos = i[0]\n",
    "        iterval = i[1]\n",
    "        iterdists = sorted([(j, np.abs(j-iterval)) for j in xvals], key=lambda x: x[1])\n",
    "        _, raw_dists = zip(*iterdists)\n",
    "        scale_fact = raw_dists[q-1]\n",
    "        scaled_dists = [(j[0],(j[1]/scale_fact)) for j in iterdists]\n",
    "        weights = [(j[0],((1-np.abs(j[1]**3))**3 if j[1]<=1 else 0)) for j in scaled_dists]\n",
    "        _, weights      = zip(*sorted(weights,     key=lambda x: x[0]))\n",
    "        _, raw_dists    = zip(*sorted(iterdists,   key=lambda x: x[0]))\n",
    "        _, scaled_dists = zip(*sorted(scaled_dists,key=lambda x: x[0]))\n",
    "        W         = np.diag(weights)\n",
    "        b         = np.linalg.inv(X.T @ W @ X) @ (X.T @ W @ yvals)\n",
    "        local_est = loc_eval(iterval, b)\n",
    "        iterDF2   = pd.DataFrame({\n",
    "                       'v'  :[iterval],\n",
    "                       'g'  :[local_est]\n",
    "                       })\n",
    "        evalDF = pd.concat([evalDF, iterDF2])\n",
    "    evalDF = evalDF[['v','g']]\n",
    "    return(evalDF)\n",
    "\n",
    "df = pd.DataFrame({\"Xvalue\" : bin_error,\n",
    "                    \"Yvalue\" : model_1_js_list\n",
    "                    })\n",
    "evalDF = loess2(\"Xvalue\", \"Yvalue\", data = df, alpha=0.7, poly_degree=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def lowess(y, x, f=2.0 / 3.0, n_iter=3):\n",
    "    \"\"\"Lowess smoother (robust locally weighted regression).\n",
    "    Fits a nonparametric regression curve to a scatterplot.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y, x : np.ndarrays\n",
    "        The arrays x and y contain an equal number of elements;\n",
    "        each pair (x[i], y[i]) defines a data point in the\n",
    "        scatterplot.\n",
    "    f : float\n",
    "        The smoothing span. A larger value will result in a\n",
    "        smoother curve.\n",
    "    n_iter : int\n",
    "        The number of robustifying iteration. Thefunction will\n",
    "        run faster with a smaller number of iterations.\n",
    "    Returns\n",
    "    -------\n",
    "    yest : np.ndarray\n",
    "        The estimated (smooth) values of y.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    r = int(np.ceil(f * n))\n",
    "    h = np.array([np.sort(np.abs(x - x[i]))[r] for i in range(n)])\n",
    "    w = np.minimum(1.0, np.maximum(np.abs((x.reshape((-1, 1)) - x.reshape((1, -1))) / h), 0.0))\n",
    "    w = (1 - w ** 3) ** 3\n",
    "    yest = np.zeros(n)\n",
    "    delta = np.ones(n)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        for i in tqdm(range(n)):\n",
    "            weights = delta * w[:, i]\n",
    "            b = np.array([np.sum(weights * y), np.sum(weights * y * x)])\n",
    "            A = np.array(\n",
    "                [\n",
    "                    [np.sum(weights), np.sum(weights * x)],\n",
    "                    [np.sum(weights * x), np.sum(weights * x * x)],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            beta = np.linalg.lstsq(A, b)[0]\n",
    "            yest[i] = beta[0] + beta[1] * x[i]\n",
    "\n",
    "        residuals = y - yest\n",
    "        s = np.median(np.abs(residuals))\n",
    "        #delta = np.clip(residuals / (6.0 * s), -1.0, 1.0)\n",
    "        delta = np.minimum(1.0, np.maximum(residuals / (6.0 * s), -1.0))\n",
    "        delta = (1 - delta ** 2) ** 2\n",
    "\n",
    "    return yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 151. GiB for an array with shape (142330, 142330) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-800e2791a301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Lowess cannot fit with large number of ties https://github.com/statsmodels/statsmodels/issues/2449\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_1_js_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#plt.plot(evalDF['v'], evalDF['g'], color='red', linewidth= 3, label=\"Fit\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9d2ba1abe968>\u001b[0m in \u001b[0;36mlowess\u001b[0;34m(y, x, f, n_iter)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0myest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 151. GiB for an array with shape (142330, 142330) and data type int64"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "#Lowess cannot fit with large number of ties https://github.com/statsmodels/statsmodels/issues/2449\n",
    "ys = lowess(model_1_js_list, bin_error)\n",
    "plt.plot(bin_error,ys,'red',linewidth=1)\n",
    "#plt.plot(evalDF['v'], evalDF['g'], color='red', linewidth= 3, label=\"Fit\")\n",
    "plt.scatter(bin_error, model_1_js_list, alpha=0.2)\n",
    "plt.title(\"JS Entropy vs Bin Error\")\n",
    "plt.xlabel('Bin Error')\n",
    "plt.ylabel('Entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 label prediction\n",
    "\n",
    "Threshold of 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two_label = lambda x: 1 if x < 0.2 else 0\n",
    "classification_two_category = list(map(lambda x: 1 if x < 0.2 else 0, model_1_js_list))\n",
    "\n",
    "X_two_train, X_two_test, y_two_train, y_two_test = train_test_split(X_test,\n",
    "                            classification_two_category,\n",
    "                            test_size=0.1, \n",
    "                            random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:46:29] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { n_trees } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-error:0.01478\n",
      "Will train until validation_0-error hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-error:0.01044\n",
      "[2]\tvalidation_0-error:0.00742\n",
      "[3]\tvalidation_0-error:0.00574\n",
      "[4]\tvalidation_0-error:0.00435\n",
      "[5]\tvalidation_0-error:0.00347\n",
      "[6]\tvalidation_0-error:0.00255\n",
      "[7]\tvalidation_0-error:0.00191\n",
      "[8]\tvalidation_0-error:0.00155\n",
      "[9]\tvalidation_0-error:0.00125\n",
      "[10]\tvalidation_0-error:0.00102\n",
      "[11]\tvalidation_0-error:0.00093\n",
      "[12]\tvalidation_0-error:0.00076\n",
      "[13]\tvalidation_0-error:0.00064\n",
      "[14]\tvalidation_0-error:0.00055\n",
      "[15]\tvalidation_0-error:0.00045\n",
      "[16]\tvalidation_0-error:0.00038\n",
      "[17]\tvalidation_0-error:0.00032\n",
      "[18]\tvalidation_0-error:0.00027\n",
      "[19]\tvalidation_0-error:0.00023\n",
      "[20]\tvalidation_0-error:0.00023\n",
      "[21]\tvalidation_0-error:0.00019\n",
      "[22]\tvalidation_0-error:0.00017\n",
      "[23]\tvalidation_0-error:0.00013\n",
      "[24]\tvalidation_0-error:0.00011\n",
      "[25]\tvalidation_0-error:0.00011\n",
      "[26]\tvalidation_0-error:0.00009\n",
      "[27]\tvalidation_0-error:0.00009\n",
      "[28]\tvalidation_0-error:0.00009\n",
      "[29]\tvalidation_0-error:0.00009\n",
      "[30]\tvalidation_0-error:0.00009\n",
      "[31]\tvalidation_0-error:0.00008\n",
      "[32]\tvalidation_0-error:0.00007\n",
      "[33]\tvalidation_0-error:0.00007\n",
      "[34]\tvalidation_0-error:0.00006\n",
      "[35]\tvalidation_0-error:0.00006\n",
      "[36]\tvalidation_0-error:0.00006\n",
      "[37]\tvalidation_0-error:0.00006\n",
      "[38]\tvalidation_0-error:0.00003\n",
      "[39]\tvalidation_0-error:0.00003\n",
      "[40]\tvalidation_0-error:0.00003\n",
      "[41]\tvalidation_0-error:0.00003\n",
      "[42]\tvalidation_0-error:0.00003\n",
      "[43]\tvalidation_0-error:0.00003\n",
      "Stopping. Best iteration:\n",
      "[38]\tvalidation_0-error:0.00003\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=20,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "       n_estimators=100, n_jobs=0, n_trees=250, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "       validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_two_model = xgb.XGBClassifier(objective=\"binary:logistic\", \n",
    "                              random_state=42, max_depth=20, scale_pos_weight=10)\n",
    "xgb_two_model.fit(X_two_train, y_two_train,\n",
    "             eval_set=[(X_two_train, y_two_train)],\n",
    "             eval_metric='error',verbose=True, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9799058525960795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds_two = xgb_two_model.predict(X_two_test)\n",
    "\n",
    "# Count the number of matches between predictions and labels\n",
    "correct_two = np.sum(preds_two == y_two_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_two = correct_two / len(y_two_test)\n",
    "print(f\"Accuracy: {accuracy_two}\")\n",
    "xgb_two_model.save_model('pred_quality_two_class.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1833,   132],\n",
       "       [  134, 12134]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "quality_model = xgb.XGBClassifier()\n",
    "quality_model.load_model('pred_quality_two_class.model')\n",
    "preds_two = quality_model.predict(X_two_test)\n",
    "display(confusion_matrix(y_two_test, preds_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 label prediction\n",
    "\n",
    "Thresholds of 0.2 and 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_three_category = list(map(lambda x: 2 if x < 0.2 else 1 if x < 0.3 else 0, model_1_js_list))\n",
    "\n",
    "X_three_train, X_three_test, y_three_train, y_three_test = train_test_split(X_test,\n",
    "                            classification_three_category,\n",
    "                            test_size=0.1, \n",
    "                            random_state=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "128097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.83822\n",
      "Will train until validation_0-mlogloss hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-mlogloss:0.65716\n",
      "[2]\tvalidation_0-mlogloss:0.52361\n",
      "[3]\tvalidation_0-mlogloss:0.42200\n",
      "[4]\tvalidation_0-mlogloss:0.34295\n",
      "[5]\tvalidation_0-mlogloss:0.28056\n",
      "[6]\tvalidation_0-mlogloss:0.23081\n",
      "[7]\tvalidation_0-mlogloss:0.19091\n",
      "[8]\tvalidation_0-mlogloss:0.15858\n",
      "[9]\tvalidation_0-mlogloss:0.13239\n",
      "[10]\tvalidation_0-mlogloss:0.11091\n",
      "[11]\tvalidation_0-mlogloss:0.09338\n",
      "[12]\tvalidation_0-mlogloss:0.07908\n",
      "[13]\tvalidation_0-mlogloss:0.06728\n",
      "[14]\tvalidation_0-mlogloss:0.05760\n",
      "[15]\tvalidation_0-mlogloss:0.04951\n",
      "[16]\tvalidation_0-mlogloss:0.04273\n",
      "[17]\tvalidation_0-mlogloss:0.03710\n",
      "[18]\tvalidation_0-mlogloss:0.03242\n",
      "[19]\tvalidation_0-mlogloss:0.02852\n",
      "[20]\tvalidation_0-mlogloss:0.02525\n",
      "[21]\tvalidation_0-mlogloss:0.02251\n",
      "[22]\tvalidation_0-mlogloss:0.02019\n",
      "[23]\tvalidation_0-mlogloss:0.01818\n",
      "[24]\tvalidation_0-mlogloss:0.01651\n",
      "[25]\tvalidation_0-mlogloss:0.01511\n",
      "[26]\tvalidation_0-mlogloss:0.01390\n",
      "[27]\tvalidation_0-mlogloss:0.01284\n",
      "[28]\tvalidation_0-mlogloss:0.01193\n",
      "[29]\tvalidation_0-mlogloss:0.01117\n",
      "[30]\tvalidation_0-mlogloss:0.01046\n",
      "[31]\tvalidation_0-mlogloss:0.00988\n",
      "[32]\tvalidation_0-mlogloss:0.00936\n",
      "[33]\tvalidation_0-mlogloss:0.00889\n",
      "[34]\tvalidation_0-mlogloss:0.00847\n",
      "[35]\tvalidation_0-mlogloss:0.00815\n",
      "[36]\tvalidation_0-mlogloss:0.00783\n",
      "[37]\tvalidation_0-mlogloss:0.00753\n",
      "[38]\tvalidation_0-mlogloss:0.00728\n",
      "[39]\tvalidation_0-mlogloss:0.00704\n",
      "[40]\tvalidation_0-mlogloss:0.00681\n",
      "[41]\tvalidation_0-mlogloss:0.00660\n",
      "[42]\tvalidation_0-mlogloss:0.00640\n",
      "[43]\tvalidation_0-mlogloss:0.00623\n",
      "[44]\tvalidation_0-mlogloss:0.00608\n",
      "[45]\tvalidation_0-mlogloss:0.00594\n",
      "[46]\tvalidation_0-mlogloss:0.00578\n",
      "[47]\tvalidation_0-mlogloss:0.00567\n",
      "[48]\tvalidation_0-mlogloss:0.00557\n",
      "[49]\tvalidation_0-mlogloss:0.00542\n",
      "[50]\tvalidation_0-mlogloss:0.00533\n",
      "[51]\tvalidation_0-mlogloss:0.00527\n",
      "[52]\tvalidation_0-mlogloss:0.00519\n",
      "[53]\tvalidation_0-mlogloss:0.00510\n",
      "[54]\tvalidation_0-mlogloss:0.00503\n",
      "[55]\tvalidation_0-mlogloss:0.00497\n",
      "[56]\tvalidation_0-mlogloss:0.00489\n",
      "[57]\tvalidation_0-mlogloss:0.00484\n",
      "[58]\tvalidation_0-mlogloss:0.00479\n",
      "[59]\tvalidation_0-mlogloss:0.00475\n",
      "[60]\tvalidation_0-mlogloss:0.00471\n",
      "[61]\tvalidation_0-mlogloss:0.00464\n",
      "[62]\tvalidation_0-mlogloss:0.00459\n",
      "[63]\tvalidation_0-mlogloss:0.00453\n",
      "[64]\tvalidation_0-mlogloss:0.00447\n",
      "[65]\tvalidation_0-mlogloss:0.00443\n",
      "[66]\tvalidation_0-mlogloss:0.00439\n",
      "[67]\tvalidation_0-mlogloss:0.00434\n",
      "[68]\tvalidation_0-mlogloss:0.00432\n",
      "[69]\tvalidation_0-mlogloss:0.00428\n",
      "[70]\tvalidation_0-mlogloss:0.00426\n",
      "[71]\tvalidation_0-mlogloss:0.00421\n",
      "[72]\tvalidation_0-mlogloss:0.00418\n",
      "[73]\tvalidation_0-mlogloss:0.00416\n",
      "[74]\tvalidation_0-mlogloss:0.00413\n",
      "[75]\tvalidation_0-mlogloss:0.00410\n",
      "[76]\tvalidation_0-mlogloss:0.00407\n",
      "[77]\tvalidation_0-mlogloss:0.00402\n",
      "[78]\tvalidation_0-mlogloss:0.00398\n",
      "[79]\tvalidation_0-mlogloss:0.00395\n",
      "[80]\tvalidation_0-mlogloss:0.00392\n",
      "[81]\tvalidation_0-mlogloss:0.00388\n",
      "[82]\tvalidation_0-mlogloss:0.00384\n",
      "[83]\tvalidation_0-mlogloss:0.00380\n",
      "[84]\tvalidation_0-mlogloss:0.00378\n",
      "[85]\tvalidation_0-mlogloss:0.00373\n",
      "[86]\tvalidation_0-mlogloss:0.00370\n",
      "[87]\tvalidation_0-mlogloss:0.00368\n",
      "[88]\tvalidation_0-mlogloss:0.00367\n",
      "[89]\tvalidation_0-mlogloss:0.00364\n",
      "[90]\tvalidation_0-mlogloss:0.00362\n",
      "[91]\tvalidation_0-mlogloss:0.00361\n",
      "[92]\tvalidation_0-mlogloss:0.00359\n",
      "[93]\tvalidation_0-mlogloss:0.00357\n",
      "[94]\tvalidation_0-mlogloss:0.00355\n",
      "[95]\tvalidation_0-mlogloss:0.00352\n",
      "[96]\tvalidation_0-mlogloss:0.00350\n",
      "[97]\tvalidation_0-mlogloss:0.00348\n",
      "[98]\tvalidation_0-mlogloss:0.00345\n",
      "[99]\tvalidation_0-mlogloss:0.00342\n",
      "[100]\tvalidation_0-mlogloss:0.00339\n",
      "[101]\tvalidation_0-mlogloss:0.00336\n",
      "[102]\tvalidation_0-mlogloss:0.00332\n",
      "[103]\tvalidation_0-mlogloss:0.00330\n",
      "[104]\tvalidation_0-mlogloss:0.00327\n",
      "[105]\tvalidation_0-mlogloss:0.00325\n",
      "[106]\tvalidation_0-mlogloss:0.00324\n",
      "[107]\tvalidation_0-mlogloss:0.00322\n",
      "[108]\tvalidation_0-mlogloss:0.00319\n",
      "[109]\tvalidation_0-mlogloss:0.00316\n",
      "[110]\tvalidation_0-mlogloss:0.00314\n",
      "[111]\tvalidation_0-mlogloss:0.00312\n",
      "[112]\tvalidation_0-mlogloss:0.00311\n",
      "[113]\tvalidation_0-mlogloss:0.00309\n",
      "[114]\tvalidation_0-mlogloss:0.00307\n",
      "[115]\tvalidation_0-mlogloss:0.00302\n",
      "[116]\tvalidation_0-mlogloss:0.00300\n",
      "[117]\tvalidation_0-mlogloss:0.00299\n",
      "[118]\tvalidation_0-mlogloss:0.00297\n",
      "[119]\tvalidation_0-mlogloss:0.00295\n",
      "[120]\tvalidation_0-mlogloss:0.00294\n",
      "[121]\tvalidation_0-mlogloss:0.00293\n",
      "[122]\tvalidation_0-mlogloss:0.00291\n",
      "[123]\tvalidation_0-mlogloss:0.00291\n",
      "[124]\tvalidation_0-mlogloss:0.00289\n",
      "[125]\tvalidation_0-mlogloss:0.00288\n",
      "[126]\tvalidation_0-mlogloss:0.00286\n",
      "[127]\tvalidation_0-mlogloss:0.00285\n",
      "[128]\tvalidation_0-mlogloss:0.00283\n",
      "[129]\tvalidation_0-mlogloss:0.00281\n",
      "[130]\tvalidation_0-mlogloss:0.00280\n",
      "[131]\tvalidation_0-mlogloss:0.00278\n",
      "[132]\tvalidation_0-mlogloss:0.00276\n",
      "[133]\tvalidation_0-mlogloss:0.00274\n",
      "[134]\tvalidation_0-mlogloss:0.00272\n",
      "[135]\tvalidation_0-mlogloss:0.00271\n",
      "[136]\tvalidation_0-mlogloss:0.00269\n",
      "[137]\tvalidation_0-mlogloss:0.00268\n",
      "[138]\tvalidation_0-mlogloss:0.00266\n",
      "[139]\tvalidation_0-mlogloss:0.00265\n",
      "[140]\tvalidation_0-mlogloss:0.00263\n",
      "[141]\tvalidation_0-mlogloss:0.00262\n",
      "[142]\tvalidation_0-mlogloss:0.00260\n",
      "[143]\tvalidation_0-mlogloss:0.00258\n",
      "[144]\tvalidation_0-mlogloss:0.00256\n",
      "[145]\tvalidation_0-mlogloss:0.00254\n",
      "[146]\tvalidation_0-mlogloss:0.00253\n",
      "[147]\tvalidation_0-mlogloss:0.00251\n",
      "[148]\tvalidation_0-mlogloss:0.00250\n",
      "[149]\tvalidation_0-mlogloss:0.00249\n",
      "[150]\tvalidation_0-mlogloss:0.00248\n",
      "[151]\tvalidation_0-mlogloss:0.00246\n",
      "[152]\tvalidation_0-mlogloss:0.00245\n",
      "[153]\tvalidation_0-mlogloss:0.00244\n",
      "[154]\tvalidation_0-mlogloss:0.00242\n",
      "[155]\tvalidation_0-mlogloss:0.00241\n",
      "[156]\tvalidation_0-mlogloss:0.00240\n",
      "[157]\tvalidation_0-mlogloss:0.00239\n",
      "[158]\tvalidation_0-mlogloss:0.00238\n",
      "[159]\tvalidation_0-mlogloss:0.00236\n",
      "[160]\tvalidation_0-mlogloss:0.00234\n",
      "[161]\tvalidation_0-mlogloss:0.00233\n",
      "[162]\tvalidation_0-mlogloss:0.00233\n",
      "[163]\tvalidation_0-mlogloss:0.00232\n",
      "[164]\tvalidation_0-mlogloss:0.00230\n",
      "[165]\tvalidation_0-mlogloss:0.00230\n",
      "[166]\tvalidation_0-mlogloss:0.00229\n",
      "[167]\tvalidation_0-mlogloss:0.00228\n",
      "[168]\tvalidation_0-mlogloss:0.00228\n",
      "[169]\tvalidation_0-mlogloss:0.00227\n",
      "[170]\tvalidation_0-mlogloss:0.00226\n",
      "[171]\tvalidation_0-mlogloss:0.00224\n",
      "[172]\tvalidation_0-mlogloss:0.00224\n",
      "[173]\tvalidation_0-mlogloss:0.00223\n",
      "[174]\tvalidation_0-mlogloss:0.00222\n",
      "[175]\tvalidation_0-mlogloss:0.00222\n",
      "[176]\tvalidation_0-mlogloss:0.00221\n",
      "[177]\tvalidation_0-mlogloss:0.00220\n",
      "[178]\tvalidation_0-mlogloss:0.00219\n",
      "[179]\tvalidation_0-mlogloss:0.00218\n",
      "[180]\tvalidation_0-mlogloss:0.00217\n",
      "[181]\tvalidation_0-mlogloss:0.00216\n",
      "[182]\tvalidation_0-mlogloss:0.00215\n",
      "[183]\tvalidation_0-mlogloss:0.00214\n",
      "[184]\tvalidation_0-mlogloss:0.00213\n",
      "[185]\tvalidation_0-mlogloss:0.00213\n",
      "[186]\tvalidation_0-mlogloss:0.00212\n",
      "[187]\tvalidation_0-mlogloss:0.00211\n",
      "[188]\tvalidation_0-mlogloss:0.00211\n",
      "[189]\tvalidation_0-mlogloss:0.00210\n",
      "[190]\tvalidation_0-mlogloss:0.00209\n",
      "[191]\tvalidation_0-mlogloss:0.00208\n",
      "[192]\tvalidation_0-mlogloss:0.00208\n",
      "[193]\tvalidation_0-mlogloss:0.00206\n",
      "[194]\tvalidation_0-mlogloss:0.00205\n",
      "[195]\tvalidation_0-mlogloss:0.00204\n",
      "[196]\tvalidation_0-mlogloss:0.00204\n",
      "[197]\tvalidation_0-mlogloss:0.00203\n",
      "[198]\tvalidation_0-mlogloss:0.00202\n",
      "[199]\tvalidation_0-mlogloss:0.00201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.2, max_delta_step=0, max_depth=25,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "       n_estimators=200, n_jobs=0, num_class=3, num_parallel_tree=1,\n",
       "       objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "       tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(X_three_train))\n",
    "display(len(y_three_train))\n",
    "xgb_three_model = xgb.XGBClassifier(objective=\"multi:softmax\", \n",
    "                              random_state=42, num_class=3, max_depth=25, learning_rate=0.2, n_estimators=200)\n",
    "xgb_three_model.fit(X_three_train, y_three_train,\n",
    "             eval_set=[(X_three_train, y_three_train)],\n",
    "             eval_metric='mlogloss',verbose=True, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9648001124148107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keh4nb/.local/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  906,   114,    19],\n",
       "       [  131,   656,   139],\n",
       "       [   11,    87, 12170]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "preds_three = xgb_three_model.predict(X_three_test)\n",
    "\n",
    "# Count the number of matches between predictions and labels\n",
    "correct_three = np.sum(preds_three == y_three_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_three = correct_three / len(y_three_test)\n",
    "print(f\"Accuracy: {accuracy_three}\")\n",
    "display(confusion_matrix(y_three_test, preds_three, labels=[0, 1, 2]))\n",
    "xgb_three_model.save_model('pred_quality_three_class.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
