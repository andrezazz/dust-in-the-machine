{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below goes through each model of the simulated data, and created training data from the output distributions. It will sample up to 101 pairs of entry in each model always including the first and last pair. It calculates delta_t (time in seconds) between the pairs and the mean of the second pair which is what we want to predict. \n",
    "\n",
    "First we did not do any transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from tqdm import notebook # Library for displaying progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are helper functions pulled out from the main code to make it easier to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(i, snapshot_count, rhod, time):\n",
    "    \"\"\" Creates a training sample from two points in time and calculates the mean of the output\"\"\"\n",
    "    # First sample will always be the first and last element\n",
    "    if i == 0:\n",
    "        idxs = [0, snapshot_count-1]\n",
    "    else:\n",
    "        # Pick two indexes for snapshots (lowest = input, highest = output)\n",
    "        idxs = sorted([random.randint(0,snapshot_count-1) for _ in range(2)])\n",
    "        \n",
    "    input_a = rhod[idxs[0]]\n",
    "    \n",
    "    # Time of the input\n",
    "    t = time[idxs[0]]\n",
    "        \n",
    "    # Difference of time in seconds between two snapshots\n",
    "    delta_t = time[idxs[1]] - t\n",
    "    \n",
    "    # Target variable is the average density of another snapshot in time\n",
    "    output_mean = np.mean(rhod[idxs[1]])\n",
    "    \n",
    "    row = np.concatenate([input_params,input_a,[t, delta_t, output_mean]])\n",
    "    return row\n",
    "\n",
    "def write_to_file(data, header=True, batch=False):\n",
    "    \"\"\" Helper method to write training data to a file\"\"\"\n",
    "    columns = ['R', 'Mstar', 'alpha', 'd2g', 'sigma', 'Tgas'] + [f'Bin_{i}' for i in range(rhod.shape[1])] + ['t','Delta_t', 'y']\n",
    "    df = pd.DataFrame(res, columns=columns)\n",
    "\n",
    "    # If writing in batch set the file mode to append\n",
    "    mode = 'a' if batch else 'w'\n",
    "    df.to_csv(filename, chunksize=100000, mode=mode, header=header, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will loop through each model, create a training row with y (average of second distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dust_training_data_small_20.csv'\n",
    "root_data_path = \"/project/SDS-capstones-kropko21/uva-astronomy/data/dust_coag_data_v1\"\n",
    "data_group = \"combined_v1\"\n",
    "\n",
    "# Store formatted data for training\n",
    "res = []\n",
    "\n",
    "chunk_size = 1000\n",
    "model_count = 10000\n",
    "writes = 0\n",
    "for d in notebook.tqdm(range(model_count)):\n",
    "    data_set = data_set = str(d).zfill(5)\n",
    "\n",
    "    data_dir = f\"{root_data_path}/{data_group}/data_{data_set}\"\n",
    "\n",
    "    input_params = None\n",
    "    # Open and extract the input parameters\n",
    "    with open(os.path.join(root_data_path, \"model_dict_v1.json\")) as f:\n",
    "        model_dict = json.load(f)\n",
    "        input_dict = model_dict[data_set]\n",
    "        input_params = [input_dict['R'], input_dict['Mstar'], input_dict['alpha'],input_dict['d2g'], input_dict['sigma'], input_dict['Tgas']]\n",
    "\n",
    "    try:\n",
    "        # `rho_dat`: The dust mass density (in g/cm^3) in each particle size/bin at a given snapshot in time. This is the main \"output\", i.e., the primary result, of any given model.\n",
    "        rhod = np.loadtxt(os.path.join(data_dir,\"rho_d.dat\"))\n",
    "        # Replace NaNs with 0s\n",
    "        rhod = np.nan_to_num(rhod)\n",
    "        \n",
    "        # `a_grid.dat`: The dust particle size in each \"bin\" in centimeters.\n",
    "        a_grid = np.loadtxt(os.path.join(data_dir, 'a_grid.dat'))\n",
    "\n",
    "        # `time.dat`: The time of each snapshot (in seconds).\n",
    "        time = np.loadtxt(os.path.join(data_dir, \"time.dat\"))\n",
    "    except Exception as e:\n",
    "        print(f'model {d} skipped')\n",
    "        import traceback\n",
    "        print(traceback.print_exc())\n",
    "        continue\n",
    "\n",
    "    snapshot_count = len(rhod)\n",
    "\n",
    "    # Set the number of samples (tried max of 10000 but jupyter kernel kept crashing)\n",
    "    if snapshot_count > 15:\n",
    "        # Set the max to 10000 for time as 150 cHr 2 is about 11000\n",
    "       samples = 100\n",
    "    else:\n",
    "        # The number of pairs\n",
    "       samples = int(math.factorial(snapshot_count) / math.factorial(2) / math.factorial(snapshot_count-2))\n",
    "    \n",
    "    samples += 1\n",
    "    for i in range(samples):\n",
    "        row = process_sample(i, snapshot_count, rhod, time)\n",
    "        res.append(row)\n",
    "        \n",
    "    # Write to csv every x models to avoid oom\n",
    "    #if d != 0 and d % chunk_size == (model_count - 1) % chunk_size:\n",
    "    #    writes += 1\n",
    "    #    # Only write the header on first chunk\n",
    "    #    header = writes == 1\n",
    "    \n",
    "# Write out the entire file at the end\n",
    "write_to_file(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>Mstar</th>\n",
       "      <th>alpha</th>\n",
       "      <th>d2g</th>\n",
       "      <th>sigma</th>\n",
       "      <th>Tgas</th>\n",
       "      <th>Bin_0</th>\n",
       "      <th>Bin_1</th>\n",
       "      <th>Bin_2</th>\n",
       "      <th>Bin_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Bin_145</th>\n",
       "      <th>Bin_146</th>\n",
       "      <th>Bin_147</th>\n",
       "      <th>Bin_148</th>\n",
       "      <th>Bin_149</th>\n",
       "      <th>Bin_150</th>\n",
       "      <th>Bin_151</th>\n",
       "      <th>t</th>\n",
       "      <th>Delta_t</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800131.000000</td>\n",
       "      <td>800131.000000</td>\n",
       "      <td>800131.0</td>\n",
       "      <td>800131.000000</td>\n",
       "      <td>800131.000000</td>\n",
       "      <td>800131.000000</td>\n",
       "      <td>800131.000000</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "      <td>8.001310e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40714.883732</td>\n",
       "      <td>69.942751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.185592</td>\n",
       "      <td>698.739173</td>\n",
       "      <td>42.074054</td>\n",
       "      <td>4.327434e+48</td>\n",
       "      <td>4.558752e+48</td>\n",
       "      <td>4.770585e+48</td>\n",
       "      <td>...</td>\n",
       "      <td>1.824384e-14</td>\n",
       "      <td>1.430676e-14</td>\n",
       "      <td>2.317453e-13</td>\n",
       "      <td>1.673062e-13</td>\n",
       "      <td>1.617644e-12</td>\n",
       "      <td>8.228013e-12</td>\n",
       "      <td>2.907163e-10</td>\n",
       "      <td>3.237179e+12</td>\n",
       "      <td>5.688001e+12</td>\n",
       "      <td>-2.268093e+40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24265.921448</td>\n",
       "      <td>108.697432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>0.362841</td>\n",
       "      <td>1657.785735</td>\n",
       "      <td>42.523274</td>\n",
       "      <td>3.870892e+51</td>\n",
       "      <td>4.077805e+51</td>\n",
       "      <td>4.267291e+51</td>\n",
       "      <td>...</td>\n",
       "      <td>3.886467e-13</td>\n",
       "      <td>2.803190e-13</td>\n",
       "      <td>5.398921e-12</td>\n",
       "      <td>1.861797e-12</td>\n",
       "      <td>3.240495e-11</td>\n",
       "      <td>1.522909e-10</td>\n",
       "      <td>2.550048e-09</td>\n",
       "      <td>5.482230e+12</td>\n",
       "      <td>7.769287e+12</td>\n",
       "      <td>1.171337e+43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.152053</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>-1.435424e-13</td>\n",
       "      <td>-1.036626e-14</td>\n",
       "      <td>-9.229458e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.509965e-248</td>\n",
       "      <td>9.182540e-198</td>\n",
       "      <td>-8.151477e-30</td>\n",
       "      <td>-1.275597e-22</td>\n",
       "      <td>-1.267761e-14</td>\n",
       "      <td>1.609918e-120</td>\n",
       "      <td>1.609918e-120</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.049262e+45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20003.000000</td>\n",
       "      <td>2.792938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.110976</td>\n",
       "      <td>10.748423</td>\n",
       "      <td>1.459631e-40</td>\n",
       "      <td>4.876662e-39</td>\n",
       "      <td>2.981931e-37</td>\n",
       "      <td>...</td>\n",
       "      <td>1.935889e-116</td>\n",
       "      <td>1.964865e-116</td>\n",
       "      <td>1.935889e-116</td>\n",
       "      <td>1.964865e-116</td>\n",
       "      <td>1.935889e-116</td>\n",
       "      <td>1.964865e-116</td>\n",
       "      <td>1.964865e-116</td>\n",
       "      <td>9.474300e+10</td>\n",
       "      <td>1.735535e+11</td>\n",
       "      <td>6.894018e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40006.000000</td>\n",
       "      <td>17.693273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>22.842133</td>\n",
       "      <td>23.773653</td>\n",
       "      <td>2.077302e-20</td>\n",
       "      <td>2.122396e-20</td>\n",
       "      <td>2.263617e-20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124160e-114</td>\n",
       "      <td>1.140858e-114</td>\n",
       "      <td>1.124160e-114</td>\n",
       "      <td>1.140858e-114</td>\n",
       "      <td>1.124160e-114</td>\n",
       "      <td>1.140858e-114</td>\n",
       "      <td>1.124160e-114</td>\n",
       "      <td>6.680990e+11</td>\n",
       "      <td>1.825145e+12</td>\n",
       "      <td>3.931639e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60009.000000</td>\n",
       "      <td>86.558651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>364.214276</td>\n",
       "      <td>59.836936</td>\n",
       "      <td>3.742349e-18</td>\n",
       "      <td>3.567534e-18</td>\n",
       "      <td>3.546004e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>7.191572e-76</td>\n",
       "      <td>9.738442e-92</td>\n",
       "      <td>2.607671e-109</td>\n",
       "      <td>4.194422e-110</td>\n",
       "      <td>5.876133e-111</td>\n",
       "      <td>2.794099e-111</td>\n",
       "      <td>1.465676e-111</td>\n",
       "      <td>3.657707e+12</td>\n",
       "      <td>8.563278e+12</td>\n",
       "      <td>3.931639e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95196.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9559.802528</td>\n",
       "      <td>177.827941</td>\n",
       "      <td>3.462514e+54</td>\n",
       "      <td>3.647599e+54</td>\n",
       "      <td>3.817093e+54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.838710e-11</td>\n",
       "      <td>4.156829e-11</td>\n",
       "      <td>4.237247e-10</td>\n",
       "      <td>3.257025e-10</td>\n",
       "      <td>1.441383e-09</td>\n",
       "      <td>6.474010e-09</td>\n",
       "      <td>5.333178e-08</td>\n",
       "      <td>3.155815e+13</td>\n",
       "      <td>3.155815e+13</td>\n",
       "      <td>1.384566e+40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R          Mstar     alpha            d2g          sigma  \\\n",
       "count  800131.000000  800131.000000  800131.0  800131.000000  800131.000000   \n",
       "mean    40714.883732      69.942751       1.0       0.016301       0.185592   \n",
       "std     24265.921448     108.697432       0.0       0.034412       0.362841   \n",
       "min         0.000000       0.316228       1.0       0.000010       0.000100   \n",
       "25%     20003.000000       2.792938       1.0       0.000100       0.001000   \n",
       "50%     40006.000000      17.693273       1.0       0.001000       0.010000   \n",
       "75%     60009.000000      86.558651       1.0       0.010000       0.100000   \n",
       "max     95196.000000     500.000000       1.0       0.100000       1.000000   \n",
       "\n",
       "                Tgas          Bin_0         Bin_1         Bin_2         Bin_3  \\\n",
       "count  800131.000000  800131.000000  8.001310e+05  8.001310e+05  8.001310e+05   \n",
       "mean      698.739173      42.074054  4.327434e+48  4.558752e+48  4.770585e+48   \n",
       "std      1657.785735      42.523274  3.870892e+51  4.077805e+51  4.267291e+51   \n",
       "min         0.152053       4.472136 -1.435424e-13 -1.036626e-14 -9.229458e-15   \n",
       "25%         2.110976      10.748423  1.459631e-40  4.876662e-39  2.981931e-37   \n",
       "50%        22.842133      23.773653  2.077302e-20  2.122396e-20  2.263617e-20   \n",
       "75%       364.214276      59.836936  3.742349e-18  3.567534e-18  3.546004e-18   \n",
       "max      9559.802528     177.827941  3.462514e+54  3.647599e+54  3.817093e+54   \n",
       "\n",
       "       ...        Bin_145        Bin_146        Bin_147        Bin_148  \\\n",
       "count  ...   8.001310e+05   8.001310e+05   8.001310e+05   8.001310e+05   \n",
       "mean   ...   1.824384e-14   1.430676e-14   2.317453e-13   1.673062e-13   \n",
       "std    ...   3.886467e-13   2.803190e-13   5.398921e-12   1.861797e-12   \n",
       "min    ... -1.509965e-248  9.182540e-198  -8.151477e-30  -1.275597e-22   \n",
       "25%    ...  1.935889e-116  1.964865e-116  1.935889e-116  1.964865e-116   \n",
       "50%    ...  1.124160e-114  1.140858e-114  1.124160e-114  1.140858e-114   \n",
       "75%    ...   7.191572e-76   9.738442e-92  2.607671e-109  4.194422e-110   \n",
       "max    ...   2.838710e-11   4.156829e-11   4.237247e-10   3.257025e-10   \n",
       "\n",
       "             Bin_149        Bin_150        Bin_151             t  \\\n",
       "count   8.001310e+05   8.001310e+05   8.001310e+05  8.001310e+05   \n",
       "mean    1.617644e-12   8.228013e-12   2.907163e-10  3.237179e+12   \n",
       "std     3.240495e-11   1.522909e-10   2.550048e-09  5.482230e+12   \n",
       "min    -1.267761e-14  1.609918e-120  1.609918e-120  0.000000e+00   \n",
       "25%    1.935889e-116  1.964865e-116  1.964865e-116  9.474300e+10   \n",
       "50%    1.124160e-114  1.140858e-114  1.124160e-114  6.680990e+11   \n",
       "75%    5.876133e-111  2.794099e-111  1.465676e-111  3.657707e+12   \n",
       "max     1.441383e-09   6.474010e-09   5.333178e-08  3.155815e+13   \n",
       "\n",
       "            Delta_t             y  \n",
       "count  8.001310e+05  8.001310e+05  \n",
       "mean   5.688001e+12 -2.268093e+40  \n",
       "std    7.769287e+12  1.171337e+43  \n",
       "min    0.000000e+00 -6.049262e+45  \n",
       "25%    1.735535e+11  6.894018e-19  \n",
       "50%    1.825145e+12  3.931639e-17  \n",
       "75%    8.563278e+12  3.931639e-15  \n",
       "max    3.155815e+13  1.384566e+40  \n",
       "\n",
       "[8 rows x 161 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df = pd.read_csv(filename)\n",
    "read_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we tried doing a log transformation on all of the bins and the resulting mean. The data had NaN and values less than 0, so we replaced these with 0. We also added a tiny constant to each one so we didn't take the log of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(i, sample_count, rhod, time):\n",
    "    \"\"\" Creates a training sample from two points in time and calculates the mean of the output\"\"\"\n",
    "    # First sample will always be the first and last element\n",
    "    if i == 0:\n",
    "        idxs = [0, snapshot_count-1]\n",
    "    else:\n",
    "        # Pick two indexes for snapshots (lowest = input, highest = output)\n",
    "        idxs = sorted([random.randint(0,snapshot_count-1) for _ in range(2)])\n",
    "        \n",
    "    # Get the input distribution of dust mass density\n",
    "    # Add a very small number to avoid taking the log of 0\n",
    "    input_a = np.log10(rhod[idxs[0]] + np.finfo(np.float64).tiny)\n",
    "\n",
    "    # Time of the input\n",
    "    t = time[idxs[0]]\n",
    "        \n",
    "    # Difference of time in seconds between two snapshots\n",
    "    delta_t = time[idxs[1]] - t\n",
    "    \n",
    "    # Target variable is the average density of another snapshot in time\n",
    "    # Add a very small number to avoid taking the log of 0\n",
    "    output_mean = np.mean(np.log10(rhod[idxs[1]] + np.finfo(np.float64).tiny))\n",
    "\n",
    "    \n",
    "    row = np.concatenate([input_params,input_a,[t, delta_t, output_mean]])\n",
    "    return row\n",
    "    \n",
    "filename = 'dust_training_data_log_v2.csv'\n",
    "root_data_path = \"/project/SDS-capstones-kropko21/uva-astronomy/data/dust_coag_data_v1\"\n",
    "data_group = \"combined_v1\"\n",
    "\n",
    "# Store formatted data for training\n",
    "res = []\n",
    "\n",
    "chunk_size = 1000\n",
    "model_count = 10000\n",
    "writes = 0\n",
    "for d in notebook.tqdm(range(model_count)):\n",
    "    data_set = data_set = str(d).zfill(5)\n",
    "\n",
    "    data_dir = f\"{root_data_path}/{data_group}/data_{data_set}\"\n",
    "\n",
    "    input_params = None\n",
    "    # Open and extract the input parameters\n",
    "    with open(os.path.join(root_data_path, \"model_dict_v1.json\")) as f:\n",
    "        model_dict = json.load(f)\n",
    "        input_dict = model_dict[data_set]\n",
    "        input_params = [input_dict['R'], input_dict['Mstar'], input_dict['alpha'],input_dict['d2g'], input_dict['sigma'], input_dict['Tgas']]\n",
    "\n",
    "    try:\n",
    "        # `rho_dat`: The dust mass density (in g/cm^3) in each particle size/bin at a given snapshot in time. This is the main \"output\", i.e., the primary result, of any given model.\n",
    "        rhod = np.loadtxt(os.path.join(data_dir,\"rho_d.dat\"))\n",
    "        # Replace NaNs with 0s\n",
    "        rhod = np.nan_to_num(rhod)\n",
    "        # Replace negative values with 0s.. is this right?\n",
    "        rhod = np.where(rhod<0, 0, rhod) \n",
    "        \n",
    "        # `a_grid.dat`: The dust particle size in each \"bin\" in centimeters.\n",
    "        a_grid = np.loadtxt(os.path.join(data_dir, 'a_grid.dat'))\n",
    "\n",
    "        # `time.dat`: The time of each snapshot (in seconds).\n",
    "        time = np.loadtxt(os.path.join(data_dir, \"time.dat\"))\n",
    "    except Exception as e:\n",
    "        print(f'model {d} skipped')\n",
    "        import traceback\n",
    "        print(traceback.print_exc())\n",
    "        continue\n",
    "\n",
    "    snapshot_count = len(rhod)\n",
    "\n",
    "    # Set the number of samples (tried max of 10000 but jupyter kernel kept crashing)\n",
    "    if snapshot_count > 15:\n",
    "        # Set the max to 10000 for time as 150 cHr 2 is about 11000\n",
    "       samples = 100\n",
    "    else:\n",
    "        # The number of pairs\n",
    "       samples = int(math.factorial(snapshot_count) / math.factorial(2) / math.factorial(snapshot_count-2))\n",
    "    \n",
    "    #OR select each pair of rows in order\n",
    "    #samples = len(rhod) - 1\n",
    "    \n",
    "    samples += 1\n",
    "    for i in range(samples):\n",
    "        row = process_sample(i, snapshot_count, rhod, time)\n",
    "        res.append(row)\n",
    "        #print(row)\n",
    "        \n",
    "    # Write to csv every x models\n",
    "    if d != 0 and d % chunk_size == (model_count - 1) % chunk_size:\n",
    "        writes += 1\n",
    "        # Only write the header on first chunk\n",
    "        header = writes == 1\n",
    "        res.clear()\n",
    "    \n",
    "# Write out the entire file at the end\n",
    "#write_to_file(res)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>Mstar</th>\n",
       "      <th>alpha</th>\n",
       "      <th>d2g</th>\n",
       "      <th>sigma</th>\n",
       "      <th>Tgas</th>\n",
       "      <th>Bin_0</th>\n",
       "      <th>Bin_1</th>\n",
       "      <th>Bin_2</th>\n",
       "      <th>Bin_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Bin_144</th>\n",
       "      <th>Bin_145</th>\n",
       "      <th>Bin_146</th>\n",
       "      <th>Bin_147</th>\n",
       "      <th>Bin_148</th>\n",
       "      <th>Bin_149</th>\n",
       "      <th>Bin_150</th>\n",
       "      <th>t</th>\n",
       "      <th>Delta_t</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.0</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>800338.000000</td>\n",
       "      <td>8.003380e+05</td>\n",
       "      <td>8.003380e+05</td>\n",
       "      <td>800338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69.939112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.185802</td>\n",
       "      <td>698.571593</td>\n",
       "      <td>42.066924</td>\n",
       "      <td>-65.815133</td>\n",
       "      <td>-63.954152</td>\n",
       "      <td>-62.047036</td>\n",
       "      <td>-59.867839</td>\n",
       "      <td>...</td>\n",
       "      <td>-91.893412</td>\n",
       "      <td>-92.115311</td>\n",
       "      <td>-90.822780</td>\n",
       "      <td>-90.380698</td>\n",
       "      <td>-90.672768</td>\n",
       "      <td>-90.707993</td>\n",
       "      <td>-90.583315</td>\n",
       "      <td>3.230440e+12</td>\n",
       "      <td>5.701342e+12</td>\n",
       "      <td>-55.824754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>108.683875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.363030</td>\n",
       "      <td>1657.638323</td>\n",
       "      <td>42.520490</td>\n",
       "      <td>94.410072</td>\n",
       "      <td>91.939246</td>\n",
       "      <td>89.493226</td>\n",
       "      <td>86.777187</td>\n",
       "      <td>...</td>\n",
       "      <td>40.341564</td>\n",
       "      <td>40.038341</td>\n",
       "      <td>42.617556</td>\n",
       "      <td>43.173690</td>\n",
       "      <td>43.455311</td>\n",
       "      <td>43.148602</td>\n",
       "      <td>43.713958</td>\n",
       "      <td>5.474076e+12</td>\n",
       "      <td>7.782881e+12</td>\n",
       "      <td>26.797276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.152053</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>...</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-192.615873</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-307.652656</td>\n",
       "      <td>-119.793196</td>\n",
       "      <td>-119.793196</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-294.263792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.792938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.110976</td>\n",
       "      <td>10.748423</td>\n",
       "      <td>-39.911313</td>\n",
       "      <td>-38.353616</td>\n",
       "      <td>-36.527678</td>\n",
       "      <td>-34.629517</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.713119</td>\n",
       "      <td>-115.706667</td>\n",
       "      <td>-115.713119</td>\n",
       "      <td>-115.706667</td>\n",
       "      <td>-115.706667</td>\n",
       "      <td>-115.705023</td>\n",
       "      <td>-115.705023</td>\n",
       "      <td>9.468949e+10</td>\n",
       "      <td>1.734984e+11</td>\n",
       "      <td>-70.106592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.693273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>22.842133</td>\n",
       "      <td>23.773653</td>\n",
       "      <td>-19.681661</td>\n",
       "      <td>-19.670043</td>\n",
       "      <td>-19.641722</td>\n",
       "      <td>-19.537965</td>\n",
       "      <td>...</td>\n",
       "      <td>-113.942768</td>\n",
       "      <td>-113.942768</td>\n",
       "      <td>-113.949172</td>\n",
       "      <td>-113.942768</td>\n",
       "      <td>-113.949172</td>\n",
       "      <td>-113.942768</td>\n",
       "      <td>-113.942768</td>\n",
       "      <td>6.657299e+11</td>\n",
       "      <td>1.825147e+12</td>\n",
       "      <td>-54.455769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.558651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>364.214276</td>\n",
       "      <td>59.836936</td>\n",
       "      <td>-17.427284</td>\n",
       "      <td>-17.450572</td>\n",
       "      <td>-17.451010</td>\n",
       "      <td>-17.373018</td>\n",
       "      <td>...</td>\n",
       "      <td>-75.994501</td>\n",
       "      <td>-96.571258</td>\n",
       "      <td>-108.635613</td>\n",
       "      <td>-109.443423</td>\n",
       "      <td>-110.260692</td>\n",
       "      <td>-110.589844</td>\n",
       "      <td>-110.856092</td>\n",
       "      <td>3.651732e+12</td>\n",
       "      <td>8.583024e+12</td>\n",
       "      <td>-37.795473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9559.802528</td>\n",
       "      <td>177.827941</td>\n",
       "      <td>-9.633772</td>\n",
       "      <td>-9.617105</td>\n",
       "      <td>-9.600438</td>\n",
       "      <td>-9.583772</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.454954</td>\n",
       "      <td>-10.381238</td>\n",
       "      <td>-9.372916</td>\n",
       "      <td>-9.475613</td>\n",
       "      <td>-8.841221</td>\n",
       "      <td>-8.188826</td>\n",
       "      <td>-7.273014</td>\n",
       "      <td>3.155815e+13</td>\n",
       "      <td>3.155815e+13</td>\n",
       "      <td>-11.760821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R     Mstar          alpha            d2g          sigma  \\\n",
       "count  800338.000000  800338.0  800338.000000  800338.000000  800338.000000   \n",
       "mean       69.939112       1.0       0.016297       0.185802     698.571593   \n",
       "std       108.683875       0.0       0.034409       0.363030    1657.638323   \n",
       "min         0.316228       1.0       0.000010       0.000100       0.152053   \n",
       "25%         2.792938       1.0       0.000100       0.001000       2.110976   \n",
       "50%        17.693273       1.0       0.001000       0.010000      22.842133   \n",
       "75%        86.558651       1.0       0.010000       0.100000     364.214276   \n",
       "max       500.000000       1.0       0.100000       1.000000    9559.802528   \n",
       "\n",
       "                Tgas          Bin_0          Bin_1          Bin_2  \\\n",
       "count  800338.000000  800338.000000  800338.000000  800338.000000   \n",
       "mean       42.066924     -65.815133     -63.954152     -62.047036   \n",
       "std        42.520490      94.410072      91.939246      89.493226   \n",
       "min         4.472136    -307.652656    -307.652656    -307.652656   \n",
       "25%        10.748423     -39.911313     -38.353616     -36.527678   \n",
       "50%        23.773653     -19.681661     -19.670043     -19.641722   \n",
       "75%        59.836936     -17.427284     -17.450572     -17.451010   \n",
       "max       177.827941      -9.633772      -9.617105      -9.600438   \n",
       "\n",
       "               Bin_3  ...        Bin_144        Bin_145        Bin_146  \\\n",
       "count  800338.000000  ...  800338.000000  800338.000000  800338.000000   \n",
       "mean      -59.867839  ...     -91.893412     -92.115311     -90.822780   \n",
       "std        86.777187  ...      40.341564      40.038341      42.617556   \n",
       "min      -307.652656  ...    -307.652656    -192.615873    -307.652656   \n",
       "25%       -34.629517  ...    -115.713119    -115.706667    -115.713119   \n",
       "50%       -19.537965  ...    -113.942768    -113.942768    -113.949172   \n",
       "75%       -17.373018  ...     -75.994501     -96.571258    -108.635613   \n",
       "max        -9.583772  ...     -10.454954     -10.381238      -9.372916   \n",
       "\n",
       "             Bin_147        Bin_148        Bin_149        Bin_150  \\\n",
       "count  800338.000000  800338.000000  800338.000000  800338.000000   \n",
       "mean      -90.380698     -90.672768     -90.707993     -90.583315   \n",
       "std        43.173690      43.455311      43.148602      43.713958   \n",
       "min      -307.652656    -307.652656    -119.793196    -119.793196   \n",
       "25%      -115.706667    -115.706667    -115.705023    -115.705023   \n",
       "50%      -113.942768    -113.949172    -113.942768    -113.942768   \n",
       "75%      -109.443423    -110.260692    -110.589844    -110.856092   \n",
       "max        -9.475613      -8.841221      -8.188826      -7.273014   \n",
       "\n",
       "                  t       Delta_t              y  \n",
       "count  8.003380e+05  8.003380e+05  800338.000000  \n",
       "mean   3.230440e+12  5.701342e+12     -55.824754  \n",
       "std    5.474076e+12  7.782881e+12      26.797276  \n",
       "min    0.000000e+00  0.000000e+00    -294.263792  \n",
       "25%    9.468949e+10  1.734984e+11     -70.106592  \n",
       "50%    6.657299e+11  1.825147e+12     -54.455769  \n",
       "75%    3.651732e+12  8.583024e+12     -37.795473  \n",
       "max    3.155815e+13  3.155815e+13     -11.760821  \n",
       "\n",
       "[8 rows x 160 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df = pd.read_csv('dust_training_data_log_v2.csv')\n",
    "read_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
