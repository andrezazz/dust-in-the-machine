{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we tried to predict the mean of the distribution from our small training data set using linear regression. We split the data into 90% train and 10% test and fit a linear regression model. We got an R^2 of less than 0 and a very high RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def create_test_train(data_set_path, test_size=0.10):\n",
    "    \"\"\" Splits a given csv file into testing and training. Target column must be y \"\"\"\n",
    "    # Make sure the columns are set\n",
    "    data_set = pd.read_csv(data_set_path)\n",
    "    \n",
    "    print(data_set.describe())\n",
    "\n",
    "    # Shuffle the data\n",
    "    data_set = data_set.sample(frac=1, random_state=0)\n",
    " \n",
    "    # Select all except y column\n",
    "    data_set_X = data_set.drop('y', axis=1)\n",
    "    # Select just y column\n",
    "    data_set_Y = data_set[['y']]\n",
    "\n",
    "    #Split into training and test data\n",
    "    return train_test_split(data_set_X,\n",
    "                            data_set_Y,\n",
    "                            test_size=test_size, \n",
    "                            random_state=300)\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    score = model.score(x, y)\n",
    "    # Time\n",
    "    pred_y = model.predict(x)\n",
    "    mse = mean_squared_error(y, pred_y)   \n",
    "    return score, mse, np.sqrt(mse)\n",
    "\n",
    "def time_preds(model, x, count=10):\n",
    "    \"\"\" Find the average runtime of making predictions on the test set\"\"\"\n",
    "    total_runtime = 0\n",
    "    for _ in range(count):\n",
    "        start = timer()\n",
    "        model.predict(x)\n",
    "        end = timer()\n",
    "        total_runtime += (end - start)\n",
    "    return total_runtime / count # Time in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   R     Mstar          alpha            d2g          sigma  \\\n",
      "count  800132.000000  800132.0  800132.000000  800132.000000  800132.000000   \n",
      "mean       69.942664       1.0       0.016301       0.185592     698.750248   \n",
      "std       108.697391       0.0       0.034412       0.362841    1657.814296   \n",
      "min         0.316228       1.0       0.000010       0.000100       0.152053   \n",
      "25%         2.792938       1.0       0.000100       0.001000       2.110976   \n",
      "50%        17.693273       1.0       0.001000       0.010000      22.842133   \n",
      "75%        86.558651       1.0       0.010000       0.100000     364.214276   \n",
      "max       500.000000       1.0       0.100000       1.000000    9559.802528   \n",
      "\n",
      "                Tgas         Bin_0         Bin_1         Bin_2         Bin_3  \\\n",
      "count  800132.000000  8.001320e+05  8.001320e+05  8.001320e+05  8.001320e+05   \n",
      "mean       42.074224  2.225405e+54  2.723183e+54  3.065637e+54  3.373757e+54   \n",
      "std        42.523518  1.990615e+57  2.435877e+57  2.742203e+57  3.017815e+57   \n",
      "min         4.472136 -1.435425e-13 -1.011777e-14 -9.018496e-15 -1.502449e-14   \n",
      "25%        10.748423  8.386722e-41  3.153533e-39  2.175778e-37  1.967365e-35   \n",
      "50%        23.773653  2.061456e-20  2.118315e-20  2.251608e-20  2.872035e-20   \n",
      "75%        59.836936  3.744092e-18  3.579019e-18  3.547729e-18  4.264151e-18   \n",
      "max       177.827941  1.780607e+60  2.178895e+60  2.452903e+60  2.699439e+60   \n",
      "\n",
      "       ...        Bin_144        Bin_145        Bin_146        Bin_147  \\\n",
      "count  ...   8.001320e+05   8.001320e+05   8.001320e+05   8.001320e+05   \n",
      "mean   ...   1.851777e-14   1.465984e-14   2.308962e-13   1.663662e-13   \n",
      "std    ...   3.940587e-13   2.927072e-13   5.342477e-12   1.749913e-12   \n",
      "min    ... -2.168124e-252  7.853032e-192  -6.751077e-30  -2.809695e-32   \n",
      "25%    ...  1.935889e-116  1.964865e-116  1.935889e-116  1.964865e-116   \n",
      "50%    ...  1.124160e-114  1.140858e-114  1.124160e-114  1.124160e-114   \n",
      "75%    ...   1.236819e-76   3.170556e-94  2.355983e-109  3.914063e-110   \n",
      "max    ...   2.423692e-11   4.156829e-11   4.237247e-10   3.313859e-10   \n",
      "\n",
      "             Bin_148        Bin_149        Bin_150             t  \\\n",
      "count   8.001320e+05   8.001320e+05   8.001320e+05  8.001320e+05   \n",
      "mean    1.621395e-12   8.235839e-12   2.901169e-10  3.227470e+12   \n",
      "std     3.248633e-11   1.525708e-10   2.546259e-09  5.474244e+12   \n",
      "min    -1.858080e-14  1.609918e-120  1.609918e-120  0.000000e+00   \n",
      "25%    1.935889e-116  1.964865e-116  1.964865e-116  9.477415e+10   \n",
      "50%    1.124160e-114  1.124160e-114  1.124160e-114  6.664636e+11   \n",
      "75%    5.876133e-111  2.794099e-111  1.465676e-111  3.643971e+12   \n",
      "max     1.441383e-09   6.474007e-09   5.333178e-08  3.155815e+13   \n",
      "\n",
      "            Delta_t             y  \n",
      "count  8.001320e+05  8.001320e+05  \n",
      "mean   5.715105e+12 -2.268087e+40  \n",
      "std    7.795674e+12  1.171336e+43  \n",
      "min    0.000000e+00 -6.049262e+45  \n",
      "25%    1.736670e+11  6.894018e-19  \n",
      "50%    1.844595e+12  3.931639e-17  \n",
      "75%    8.610633e+12  3.931639e-15  \n",
      "max    3.155815e+13  1.384566e+40  \n",
      "\n",
      "[8 rows x 160 columns]\n",
      "R2:-2.4452964498868894e+22, MSE:2.8229937234860903e+80, RMSE:1.6801766941265703e+40\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = create_test_train(\"dust_training_data_small.csv\")\n",
    "\n",
    "# Fit a linear regresison on the training set\n",
    "fit_linear = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# See how our linear regression fit does\n",
    "eval_linear = evaluate_model(fit_linear, X_test, y_test)\n",
    "print(f\"R2:{eval_linear[0]}, MSE:{eval_linear[1]}, RMSE:{eval_linear[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we measure the runtime of making predictions on the mean. On average it takes 2.1E-07 to make a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01680419290205464 seconds for 80014 preds. 2.1001565853543927e-07 seconds per prediction\n"
     ]
    }
   ],
   "source": [
    "runtime = time_preds(fit_linear, X_test)\n",
    "print(f\"{runtime} seconds for {len(X_test)} preds. {runtime/len(X_test)} seconds per prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we used the data set that took the log transform of all of the density bins and the average y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   R     Mstar          alpha            d2g          sigma  \\\n",
      "count  800338.000000  800338.0  800338.000000  800338.000000  800338.000000   \n",
      "mean       69.939112       1.0       0.016297       0.185802     698.571593   \n",
      "std       108.683875       0.0       0.034409       0.363030    1657.638323   \n",
      "min         0.316228       1.0       0.000010       0.000100       0.152053   \n",
      "25%         2.792938       1.0       0.000100       0.001000       2.110976   \n",
      "50%        17.693273       1.0       0.001000       0.010000      22.842133   \n",
      "75%        86.558651       1.0       0.010000       0.100000     364.214276   \n",
      "max       500.000000       1.0       0.100000       1.000000    9559.802528   \n",
      "\n",
      "                Tgas          Bin_0          Bin_1          Bin_2  \\\n",
      "count  800338.000000  800338.000000  800338.000000  800338.000000   \n",
      "mean       42.066924     -65.815133     -63.954152     -62.047036   \n",
      "std        42.520490      94.410072      91.939246      89.493226   \n",
      "min         4.472136    -307.652656    -307.652656    -307.652656   \n",
      "25%        10.748423     -39.911313     -38.353616     -36.527678   \n",
      "50%        23.773653     -19.681661     -19.670043     -19.641722   \n",
      "75%        59.836936     -17.427284     -17.450572     -17.451010   \n",
      "max       177.827941      -9.633772      -9.617105      -9.600438   \n",
      "\n",
      "               Bin_3  ...        Bin_144        Bin_145        Bin_146  \\\n",
      "count  800338.000000  ...  800338.000000  800338.000000  800338.000000   \n",
      "mean      -59.867839  ...     -91.893412     -92.115311     -90.822780   \n",
      "std        86.777187  ...      40.341564      40.038341      42.617556   \n",
      "min      -307.652656  ...    -307.652656    -192.615873    -307.652656   \n",
      "25%       -34.629517  ...    -115.713119    -115.706667    -115.713119   \n",
      "50%       -19.537965  ...    -113.942768    -113.942768    -113.949172   \n",
      "75%       -17.373018  ...     -75.994501     -96.571258    -108.635613   \n",
      "max        -9.583772  ...     -10.454954     -10.381238      -9.372916   \n",
      "\n",
      "             Bin_147        Bin_148        Bin_149        Bin_150  \\\n",
      "count  800338.000000  800338.000000  800338.000000  800338.000000   \n",
      "mean      -90.380698     -90.672768     -90.707993     -90.583315   \n",
      "std        43.173690      43.455311      43.148602      43.713958   \n",
      "min      -307.652656    -307.652656    -119.793196    -119.793196   \n",
      "25%      -115.706667    -115.706667    -115.705023    -115.705023   \n",
      "50%      -113.942768    -113.949172    -113.942768    -113.942768   \n",
      "75%      -109.443423    -110.260692    -110.589844    -110.856092   \n",
      "max        -9.475613      -8.841221      -8.188826      -7.273014   \n",
      "\n",
      "                  t       Delta_t              y  \n",
      "count  8.003380e+05  8.003380e+05  800338.000000  \n",
      "mean   3.230440e+12  5.701342e+12     -55.824754  \n",
      "std    5.474076e+12  7.782881e+12      26.797276  \n",
      "min    0.000000e+00  0.000000e+00    -294.263792  \n",
      "25%    9.468949e+10  1.734984e+11     -70.106592  \n",
      "50%    6.657299e+11  1.825147e+12     -54.455769  \n",
      "75%    3.651732e+12  8.583024e+12     -37.795473  \n",
      "max    3.155815e+13  3.155815e+13     -11.760821  \n",
      "\n",
      "[8 rows x 160 columns]\n",
      "R2:0.7473794929827201, MSE:182.84065933458126, RMSE:13.521858575454088\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = create_test_train(\"dust_training_data_log_v2.csv\")\n",
    "\n",
    "# Fit our linear regression with log transformed data the training set\n",
    "fit_log = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# See how our linear regression fit does with the log transformed data\n",
    "eval_linear_log = evaluate_model(fit_log, X_test, y_test)\n",
    "print(f\"R2:{eval_linear_log[0]}, MSE:{eval_linear_log[1]}, RMSE:{eval_linear_log[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next tried to fit an elastic net model on the log transformed data. It performed about the same as linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.001 L1: 1.0 R2:0.7345378901326389, MSE:190.53321265752945, RMSE:13.803376857042245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Try cross-validation for selecting\n",
    "alphas = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1]\n",
    "l1_ratio = [0.01, .1, .5, .7, .9, .95, 1]\n",
    "fit_elastic_net = ElasticNetCV(cv=10, random_state=0, normalize=True, alphas=alphas, l1_ratio=l1_ratio, max_iter=100000)\n",
    "\n",
    "# Fit our model\n",
    "fit_elastic_net.fit(X_train, column_or_1d(y_train))\n",
    "\n",
    "# Get the evaluation metrics\n",
    "eval_elastic_net = evaluate_model(fit_elastic_net, X_test, y_test)\n",
    "print(f\"Alpha:{fit_elastic_net.alpha_} L1: {fit_elastic_net.l1_ratio_} R2:{eval_elastic_net[0]}, MSE:{eval_elastic_net[1]}, RMSE:{eval_elastic_net[2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
